{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_hFHFn2JpqK"
      },
      "outputs": [],
      "source": [
        "#IndicTrans2 trained on Scientific Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJ_sKev24dLT",
        "outputId": "ed276333-d800-41c6-a1ae-f89592838f9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Scientific_Dataset_Parallel'...\n",
            "remote: Enumerating objects: 21, done.\u001b[K\n",
            "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 21 (delta 1), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (21/21), 704.71 KiB | 4.89 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/kpardhasai2004/Scientific_Dataset_Parallel.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1P-N3N04hVl",
        "outputId": "e69f0866-1cf6-4613-d7bf-81da4ab8afda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft) (4.48.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.3.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft) (0.5.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from peft) (0.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (2024.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (0.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2025.1.31)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Cloning into 'IndicTrans2'...\n",
            "remote: Enumerating objects: 759, done.\u001b[K\n",
            "remote: Counting objects: 100% (174/174), done.\u001b[K\n",
            "remote: Compressing objects: 100% (71/71), done.\u001b[K\n",
            "remote: Total 759 (delta 148), reused 103 (delta 103), pack-reused 585 (from 3)\u001b[K\n",
            "Receiving objects: 100% (759/759), 4.15 MiB | 17.20 MiB/s, done.\n",
            "Resolving deltas: 100% (490/490), done.\n",
            "/content/IndicTrans2/huggingface_interface\n",
            "Setting up the environment in the /content/IndicTrans2/huggingface_interface\n",
            "Creating a virtual environment with python3\n",
            "install.sh: line 10: conda: command not found\n",
            "install.sh: line 11: conda: command not found\n",
            "Installing all the dependencies\n",
            "install.sh: line 14: conda: command not found\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.0.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Downloading pip-25.0.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.0.1\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Cloning into 'IndicTransToolkit'...\n",
            "remote: Enumerating objects: 222, done.\u001b[K\n",
            "remote: Counting objects: 100% (127/127), done.\u001b[K\n",
            "remote: Compressing objects: 100% (70/70), done.\u001b[K\n",
            "remote: Total 222 (delta 61), reused 97 (delta 47), pack-reused 95 (from 1)\u001b[K\n",
            "Receiving objects: 100% (222/222), 4.38 MiB | 18.02 MiB/s, done.\n",
            "Resolving deltas: 100% (89/89), done.\n",
            "Obtaining file:///content/IndicTrans2/huggingface_interface/IndicTransToolkit\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library.git (from IndicTransToolkit==1.0.3)\n",
            "  Cloning https://github.com/VarunGumma/indic_nlp_library.git to /tmp/pip-install-_9v_od6d/indic-nlp-library-it2_f91855b542cf403690eaf62bd1b1a92f\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/VarunGumma/indic_nlp_library.git /tmp/pip-install-_9v_od6d/indic-nlp-library-it2_f91855b542cf403690eaf62bd1b1a92f\n",
            "  Resolved https://github.com/VarunGumma/indic_nlp_library.git to commit 342a7e95735e88949528bdca371518cb0ba5bb5d\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools>=68.2.2 in /usr/local/lib/python3.11/dist-packages (from IndicTransToolkit==1.0.3) (75.1.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from IndicTransToolkit==1.0.3) (2.6.0+cu124)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.11/dist-packages (from IndicTransToolkit==1.0.3) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.11/dist-packages (from IndicTransToolkit==1.0.3) (0.1.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from IndicTransToolkit==1.0.3) (0.2.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from IndicTransToolkit==1.0.3) (4.48.3)\n",
            "Collecting sacrebleu (from IndicTransToolkit==1.0.3)\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "Collecting sphinx-argparse (from indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library.git->IndicTransToolkit==1.0.3)\n",
            "  Downloading sphinx_argparse-0.5.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting sphinx_rtd_theme (from indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library.git->IndicTransToolkit==1.0.3)\n",
            "  Downloading sphinx_rtd_theme-3.0.2-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting morfessor (from indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library.git->IndicTransToolkit==1.0.3)\n",
            "  Downloading Morfessor-2.0.6-py3-none-any.whl.metadata (628 bytes)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library.git->IndicTransToolkit==1.0.3) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library.git->IndicTransToolkit==1.0.3) (1.26.4)\n",
            "Collecting portalocker (from sacrebleu->IndicTransToolkit==1.0.3)\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu->IndicTransToolkit==1.0.3) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu->IndicTransToolkit==1.0.3) (0.9.0)\n",
            "Collecting colorama (from sacrebleu->IndicTransToolkit==1.0.3)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu->IndicTransToolkit==1.0.3) (5.3.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from sacremoses->IndicTransToolkit==1.0.3) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from sacremoses->IndicTransToolkit==1.0.3) (1.4.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sacremoses->IndicTransToolkit==1.0.3) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->IndicTransToolkit==1.0.3) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->IndicTransToolkit==1.0.3) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->IndicTransToolkit==1.0.3) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->IndicTransToolkit==1.0.3) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->IndicTransToolkit==1.0.3) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->IndicTransToolkit==1.0.3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->IndicTransToolkit==1.0.3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->IndicTransToolkit==1.0.3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->IndicTransToolkit==1.0.3) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->IndicTransToolkit==1.0.3) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->IndicTransToolkit==1.0.3) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->IndicTransToolkit==1.0.3) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->IndicTransToolkit==1.0.3) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->IndicTransToolkit==1.0.3) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->IndicTransToolkit==1.0.3) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->IndicTransToolkit==1.0.3) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->IndicTransToolkit==1.0.3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->IndicTransToolkit==1.0.3) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->IndicTransToolkit==1.0.3) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->IndicTransToolkit==1.0.3) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->IndicTransToolkit==1.0.3) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers->IndicTransToolkit==1.0.3) (0.28.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers->IndicTransToolkit==1.0.3) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers->IndicTransToolkit==1.0.3) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers->IndicTransToolkit==1.0.3) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->IndicTransToolkit==1.0.3) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers->IndicTransToolkit==1.0.3) (0.5.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->IndicTransToolkit==1.0.3) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library.git->IndicTransToolkit==1.0.3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library.git->IndicTransToolkit==1.0.3) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library.git->IndicTransToolkit==1.0.3) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->IndicTransToolkit==1.0.3) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->IndicTransToolkit==1.0.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->IndicTransToolkit==1.0.3) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->IndicTransToolkit==1.0.3) (2025.1.31)\n",
            "Requirement already satisfied: sphinx>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library.git->IndicTransToolkit==1.0.3) (8.1.3)\n",
            "Requirement already satisfied: docutils>=0.19 in /usr/local/lib/python3.11/dist-packages (from sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library.git->IndicTransToolkit==1.0.3) (0.21.2)\n",
            "Collecting sphinxcontrib-jquery<5,>=4 (from sphinx_rtd_theme->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library.git->IndicTransToolkit==1.0.3)\n",
            "  Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library.git->IndicTransToolkit==1.0.3) (1.17.0)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library.git->IndicTransToolkit==1.0.3) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library.git->IndicTransToolkit==1.0.3) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library.git->IndicTransToolkit==1.0.3) (2.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library.git->IndicTransToolkit==1.0.3) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library.git->IndicTransToolkit==1.0.3) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library.git->IndicTransToolkit==1.0.3) (2.0.0)\n",
            "Requirement already satisfied: Pygments>=2.17 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library.git->IndicTransToolkit==1.0.3) (2.18.0)\n",
            "Requirement already satisfied: snowballstemmer>=2.2 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library.git->IndicTransToolkit==1.0.3) (2.2.0)\n",
            "Requirement already satisfied: babel>=2.13 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library.git->IndicTransToolkit==1.0.3) (2.17.0)\n",
            "Requirement already satisfied: alabaster>=0.7.14 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library.git->IndicTransToolkit==1.0.3) (1.0.0)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library.git->IndicTransToolkit==1.0.3) (1.4.1)\n",
            "Downloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n",
            "Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Downloading sphinx_argparse-0.5.2-py3-none-any.whl (12 kB)\n",
            "Downloading sphinx_rtd_theme-3.0.2-py2.py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m135.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n",
            "Building wheels for collected packages: IndicTransToolkit, indic-nlp-library-IT2\n",
            "  Building editable for IndicTransToolkit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for IndicTransToolkit: filename=indictranstoolkit-1.0.3-0.editable-cp311-cp311-linux_x86_64.whl size=6231 sha256=44d345e85e052a89706f861ef823eb791c114091438067943ae27e0ccab95fdc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-lwq53iod/wheels/cd/d6/69/93b087e184d23ff1d423e9092f2d3bb99a8726a668f984156e\n",
            "  Building wheel for indic-nlp-library-IT2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for indic-nlp-library-IT2: filename=indic_nlp_library_IT2-0.0.2-py3-none-any.whl size=48116 sha256=8edde61a09a2e9eb1f945739b6e55419079abdc59394ef4eb2562ef56241a855\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-lwq53iod/wheels/e2/c8/a2/d1cbc08e622d9dac683c5fdc3fd7f0b2216ae6425cfa25be24\n",
            "Successfully built IndicTransToolkit indic-nlp-library-IT2\n",
            "Installing collected packages: morfessor, portalocker, colorama, sacrebleu, sphinxcontrib-jquery, sphinx-argparse, sphinx_rtd_theme, indic-nlp-library-IT2, IndicTransToolkit\n",
            "Successfully installed IndicTransToolkit-1.0.3 colorama-0.4.6 indic-nlp-library-IT2-0.0.2 morfessor-2.0.6 portalocker-3.1.1 sacrebleu-2.5.1 sphinx-argparse-0.5.2 sphinx_rtd_theme-3.0.2 sphinxcontrib-jquery-4.1\n",
            "Setup completed!\n"
          ]
        }
      ],
      "source": [
        "!pip install peft\n",
        "!git clone https://github.com/AI4Bharat/IndicTrans2\n",
        "%cd IndicTrans2/huggingface_interface\n",
        "!source install.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vf2rQZ94YDJ",
        "outputId": "07d16d84-61b3-4597-8caa-8d0272c2661e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-03-14 16:40:01.953542: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1741970402.307516    2499 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1741970402.411657    2499 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-14 16:40:03.068182: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            " | > Loading ai4bharat/indictrans2-en-indic-dist-200M and tokenizer ...\n",
            "config.json: 100% 1.35k/1.35k [00:00<00:00, 7.55MB/s]\n",
            "configuration_indictrans.py: 100% 14.2k/14.2k [00:00<00:00, 11.8MB/s]\n",
            "A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-en-indic-dist-200M:\n",
            "- configuration_indictrans.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "modeling_indictrans.py: 100% 79.8k/79.8k [00:00<00:00, 1.62MB/s]\n",
            "A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-en-indic-dist-200M:\n",
            "- modeling_indictrans.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "model.safetensors: 100% 1.10G/1.10G [00:12<00:00, 89.8MB/s]\n",
            "generation_config.json: 100% 163/163 [00:00<00:00, 1.37MB/s]\n",
            "tokenizer_config.json: 100% 1.11k/1.11k [00:00<00:00, 9.41MB/s]\n",
            "tokenization_indictrans.py: 100% 8.13k/8.13k [00:00<00:00, 44.4MB/s]\n",
            "A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-en-indic-dist-200M:\n",
            "- tokenization_indictrans.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "dict.SRC.json: 100% 645k/645k [00:00<00:00, 3.15MB/s]\n",
            "dict.TGT.json: 100% 3.39M/3.39M [00:00<00:00, 3.99MB/s]\n",
            "model.SRC: 100% 759k/759k [00:00<00:00, 40.4MB/s]\n",
            "model.TGT: 100% 3.26M/3.26M [00:00<00:00, 107MB/s]\n",
            "special_tokens_map.json: 100% 96.0/96.0 [00:00<00:00, 754kB/s]\n",
            "Map (num_proc=8):   0% 0/887 [00:00<?, ? examples/s]/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3961: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "Map (num_proc=8):  13% 111/887 [00:01<00:13, 55.92 examples/s]/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3961: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "Map (num_proc=8):  25% 222/887 [00:03<00:09, 73.09 examples/s]/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3961: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "Map (num_proc=8):  38% 333/887 [00:04<00:06, 82.12 examples/s]/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3961: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "Map (num_proc=8):  50% 444/887 [00:05<00:05, 84.68 examples/s]/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3961: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "Map (num_proc=8):  63% 555/887 [00:06<00:03, 85.18 examples/s]/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3961: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "Map (num_proc=8):  75% 666/887 [00:08<00:02, 86.69 examples/s]/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3961: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "Map (num_proc=8):  88% 777/887 [00:09<00:01, 88.79 examples/s]/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3961: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "Map (num_proc=8): 100% 887/887 [00:10<00:00, 83.15 examples/s]\n",
            " | > Loaded train dataset from /content/Scientific_Dataset_Parallel/en-indic-exp. Size: 887 ...\n",
            "Map (num_proc=8):   0% 0/884 [00:00<?, ? examples/s]/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3961: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "Map (num_proc=8):  13% 111/884 [00:01<00:11, 70.03 examples/s]/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3961: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "Map (num_proc=8):  25% 222/884 [00:02<00:07, 83.67 examples/s]/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3961: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "Map (num_proc=8):  38% 333/884 [00:03<00:06, 87.17 examples/s]/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3961: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "Map (num_proc=8):  50% 444/884 [00:05<00:04, 89.04 examples/s]/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3961: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "Map (num_proc=8):  63% 554/884 [00:06<00:03, 90.16 examples/s]/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3961: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "Map (num_proc=8):  75% 664/884 [00:07<00:02, 90.30 examples/s]/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3961: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "Map (num_proc=8):  88% 774/884 [00:08<00:01, 88.82 examples/s]/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3961: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "Map (num_proc=8): 100% 884/884 [00:10<00:00, 82.59 examples/s]\n",
            " | > Loaded eval dataset from /content/Scientific_Dataset_Parallel/en-indic-exp. Size: 884 ...\n",
            "trainable params: 1,769,472 || all params: 213,545,984 || trainable%: 0.8286\n",
            " | > Loading metrics factory with BLEU and chrF ...\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            " | > Starting training ...\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "{'loss': 1.174, 'grad_norm': 0.1726948618888855, 'learning_rate': 5e-06, 'epoch': 3.58, 'num_input_tokens_seen': 338752}\n",
            "{'loss': 1.1592, 'grad_norm': 0.20117685198783875, 'learning_rate': 1e-05, 'epoch': 7.14, 'num_input_tokens_seen': 673632}\n",
            "{'loss': 1.151, 'grad_norm': 0.15840178728103638, 'learning_rate': 1.5e-05, 'epoch': 10.72, 'num_input_tokens_seen': 1010008}\n",
            "{'loss': 1.1056, 'grad_norm': 0.14993086457252502, 'learning_rate': 2e-05, 'epoch': 14.29, 'num_input_tokens_seen': 1341576}\n",
            "{'loss': 1.0657, 'grad_norm': 0.3225747346878052, 'learning_rate': 2.5e-05, 'epoch': 17.86, 'num_input_tokens_seen': 1672704}\n",
            "{'loss': 1.0497, 'grad_norm': 0.32005420327186584, 'learning_rate': 3e-05, 'epoch': 21.43, 'num_input_tokens_seen': 2005792}\n",
            "{'loss': 1.022, 'grad_norm': 0.27743446826934814, 'learning_rate': 3.5e-05, 'epoch': 25.0, 'num_input_tokens_seen': 2340104}\n",
            "{'loss': 0.998, 'grad_norm': 0.25931620597839355, 'learning_rate': 4e-05, 'epoch': 28.58, 'num_input_tokens_seen': 2678976}\n",
            "{'loss': 0.9576, 'grad_norm': 0.2479638010263443, 'learning_rate': 4.5e-05, 'epoch': 32.14, 'num_input_tokens_seen': 3013800}\n",
            "{'loss': 0.9376, 'grad_norm': 0.27869999408721924, 'learning_rate': 5e-05, 'epoch': 35.72, 'num_input_tokens_seen': 3349856}\n",
            "100% 1000/1000 [15:52<00:00,  1.01it/s]Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "\n",
            "  0% 0/111 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 2/111 [00:13<12:15,  6.74s/it]\u001b[A\n",
            "  3% 3/111 [00:26<16:57,  9.42s/it]\u001b[A\n",
            "  4% 4/111 [00:39<19:19, 10.83s/it]\u001b[A\n",
            "  5% 5/111 [00:52<20:19, 11.51s/it]\u001b[A\n",
            "  5% 6/111 [01:03<19:37, 11.21s/it]\u001b[A\n",
            "  6% 7/111 [01:13<19:00, 10.96s/it]\u001b[A\n",
            "  7% 8/111 [01:20<16:36,  9.68s/it]\u001b[A\n",
            "  8% 9/111 [01:28<15:27,  9.09s/it]\u001b[A\n",
            "  9% 10/111 [01:34<13:43,  8.15s/it]\u001b[A\n",
            " 10% 11/111 [01:41<13:09,  7.89s/it]\u001b[A\n",
            " 11% 12/111 [01:46<11:28,  6.95s/it]\u001b[A\n",
            " 12% 13/111 [01:51<10:34,  6.48s/it]\u001b[A\n",
            " 13% 14/111 [01:55<09:09,  5.67s/it]\u001b[A\n",
            " 14% 15/111 [01:59<08:08,  5.08s/it]\u001b[A\n",
            " 14% 16/111 [02:03<07:41,  4.86s/it]\u001b[A\n",
            " 15% 17/111 [02:06<06:44,  4.30s/it]\u001b[A\n",
            " 16% 18/111 [02:10<06:12,  4.00s/it]\u001b[A\n",
            " 17% 19/111 [02:12<05:35,  3.65s/it]\u001b[A\n",
            " 18% 20/111 [02:16<05:23,  3.56s/it]\u001b[A\n",
            " 19% 21/111 [02:18<04:38,  3.09s/it]\u001b[A\n",
            " 20% 22/111 [02:20<04:03,  2.73s/it]\u001b[A\n",
            " 21% 23/111 [02:21<03:36,  2.45s/it]\u001b[A\n",
            " 22% 24/111 [02:23<03:04,  2.12s/it]\u001b[A\n",
            " 23% 25/111 [02:24<02:46,  1.94s/it]\u001b[A\n",
            " 23% 26/111 [02:25<02:21,  1.67s/it]\u001b[A\n",
            " 24% 27/111 [02:26<02:07,  1.51s/it]\u001b[A\n",
            " 25% 28/111 [02:40<06:58,  5.05s/it]\u001b[A\n",
            " 26% 29/111 [02:53<10:26,  7.64s/it]\u001b[A\n",
            " 27% 30/111 [03:07<12:37,  9.35s/it]\u001b[A\n",
            " 28% 31/111 [03:20<13:55, 10.44s/it]\u001b[A\n",
            " 29% 32/111 [03:30<13:36, 10.34s/it]\u001b[A\n",
            " 30% 33/111 [03:40<13:15, 10.20s/it]\u001b[A\n",
            " 31% 34/111 [03:48<12:24,  9.66s/it]\u001b[A\n",
            " 32% 35/111 [03:55<11:09,  8.80s/it]\u001b[A\n",
            " 32% 36/111 [04:02<10:09,  8.13s/it]\u001b[A\n",
            " 33% 37/111 [04:07<08:54,  7.22s/it]\u001b[A\n",
            " 34% 38/111 [04:13<08:20,  6.85s/it]\u001b[A\n",
            " 35% 39/111 [04:17<07:29,  6.24s/it]\u001b[A\n",
            " 36% 40/111 [04:22<06:53,  5.82s/it]\u001b[A\n",
            " 37% 41/111 [04:27<06:20,  5.43s/it]\u001b[A\n",
            " 38% 42/111 [04:31<05:42,  4.96s/it]\u001b[A\n",
            " 39% 43/111 [04:35<05:30,  4.86s/it]\u001b[A\n",
            " 40% 44/111 [04:39<05:01,  4.50s/it]\u001b[A\n",
            " 41% 45/111 [04:42<04:34,  4.16s/it]\u001b[A\n",
            " 41% 46/111 [04:45<04:06,  3.79s/it]\u001b[A\n",
            " 42% 47/111 [04:49<03:55,  3.69s/it]\u001b[A\n",
            " 43% 48/111 [04:51<03:28,  3.31s/it]\u001b[A\n",
            " 44% 49/111 [04:53<03:06,  3.00s/it]\u001b[A\n",
            " 45% 50/111 [04:55<02:41,  2.65s/it]\u001b[A\n",
            " 46% 51/111 [04:57<02:21,  2.35s/it]\u001b[A\n",
            " 47% 52/111 [04:59<02:06,  2.14s/it]\u001b[A\n",
            " 48% 53/111 [05:00<01:59,  2.06s/it]\u001b[A\n",
            " 49% 54/111 [05:02<01:43,  1.82s/it]\u001b[A\n",
            " 50% 55/111 [05:15<04:53,  5.24s/it]\u001b[A\n",
            " 50% 56/111 [05:28<06:58,  7.61s/it]\u001b[A\n",
            " 51% 57/111 [05:41<08:23,  9.33s/it]\u001b[A\n",
            " 52% 58/111 [05:53<08:54, 10.08s/it]\u001b[A\n",
            " 53% 59/111 [06:03<08:42, 10.04s/it]\u001b[A\n",
            " 54% 60/111 [06:11<07:54,  9.30s/it]\u001b[A\n",
            " 55% 61/111 [06:18<07:18,  8.77s/it]\u001b[A\n",
            " 56% 62/111 [06:24<06:28,  7.93s/it]\u001b[A\n",
            " 57% 63/111 [06:30<05:55,  7.40s/it]\u001b[A\n",
            " 58% 64/111 [06:36<05:21,  6.84s/it]\u001b[A\n",
            " 59% 65/111 [06:41<04:52,  6.37s/it]\u001b[A\n",
            " 59% 66/111 [06:47<04:37,  6.16s/it]\u001b[A\n",
            " 60% 67/111 [06:52<04:13,  5.75s/it]\u001b[A\n",
            " 61% 68/111 [06:57<03:56,  5.51s/it]\u001b[A\n",
            " 62% 69/111 [07:00<03:31,  5.04s/it]\u001b[A\n",
            " 63% 70/111 [07:04<03:08,  4.61s/it]\u001b[A\n",
            " 64% 71/111 [07:08<02:53,  4.34s/it]\u001b[A\n",
            " 65% 72/111 [07:11<02:40,  4.12s/it]\u001b[A\n",
            " 66% 73/111 [07:14<02:20,  3.70s/it]\u001b[A\n",
            " 67% 74/111 [07:17<02:02,  3.30s/it]\u001b[A\n",
            " 68% 75/111 [07:18<01:42,  2.84s/it]\u001b[A\n",
            " 68% 76/111 [07:20<01:32,  2.65s/it]\u001b[A\n",
            " 69% 77/111 [07:23<01:25,  2.52s/it]\u001b[A\n",
            " 70% 78/111 [07:24<01:11,  2.17s/it]\u001b[A\n",
            " 71% 79/111 [07:25<01:00,  1.90s/it]\u001b[A\n",
            " 72% 80/111 [07:26<00:51,  1.65s/it]\u001b[A\n",
            " 73% 81/111 [07:27<00:43,  1.46s/it]\u001b[A\n",
            " 74% 82/111 [07:41<02:24,  4.98s/it]\u001b[A\n",
            " 75% 83/111 [07:54<03:30,  7.51s/it]\u001b[A\n",
            " 76% 84/111 [08:07<04:06,  9.12s/it]\u001b[A\n",
            " 77% 85/111 [08:18<04:09,  9.59s/it]\u001b[A\n",
            " 77% 86/111 [08:26<03:52,  9.32s/it]\u001b[A\n",
            " 78% 87/111 [08:33<03:26,  8.62s/it]\u001b[A\n",
            " 79% 88/111 [08:41<03:13,  8.39s/it]\u001b[A\n",
            " 80% 89/111 [08:48<02:54,  7.92s/it]\u001b[A\n",
            " 81% 90/111 [08:55<02:42,  7.71s/it]\u001b[A\n",
            " 82% 91/111 [09:01<02:24,  7.21s/it]\u001b[A\n",
            " 83% 92/111 [09:07<02:10,  6.84s/it]\u001b[A\n",
            " 84% 93/111 [09:18<02:25,  8.10s/it]\u001b[A\n",
            " 85% 94/111 [09:23<02:01,  7.12s/it]\u001b[A\n",
            " 86% 95/111 [09:27<01:40,  6.29s/it]\u001b[A\n",
            " 86% 96/111 [09:32<01:26,  5.77s/it]\u001b[A\n",
            " 87% 97/111 [09:36<01:11,  5.13s/it]\u001b[A\n",
            " 88% 98/111 [09:39<00:59,  4.59s/it]\u001b[A\n",
            " 89% 99/111 [09:43<00:51,  4.32s/it]\u001b[A\n",
            " 90% 100/111 [09:45<00:41,  3.81s/it]\u001b[A\n",
            " 91% 101/111 [09:48<00:34,  3.44s/it]\u001b[A\n",
            " 92% 102/111 [09:50<00:28,  3.14s/it]\u001b[A\n",
            " 93% 103/111 [09:53<00:23,  2.88s/it]\u001b[A\n",
            " 94% 104/111 [09:55<00:19,  2.84s/it]\u001b[A\n",
            " 95% 105/111 [09:57<00:15,  2.50s/it]\u001b[A\n",
            " 95% 106/111 [09:59<00:11,  2.21s/it]\u001b[A\n",
            " 96% 107/111 [10:00<00:07,  1.88s/it]\u001b[A\n",
            " 97% 108/111 [10:01<00:04,  1.63s/it]\u001b[A\n",
            " 98% 109/111 [10:14<00:09,  4.99s/it]\u001b[A\n",
            " 99% 110/111 [10:19<00:05,  5.02s/it]\u001b[A\n",
            "100% 111/111 [10:22<00:00,  4.64s/it]\u001b[A/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3961: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 1.0472748279571533, 'eval_BLEU': 33.363746226990905, 'eval_chrF': 66.05018908624973, 'eval_runtime': 642.3102, 'eval_samples_per_second': 1.376, 'eval_steps_per_second': 0.173, 'epoch': 35.72, 'num_input_tokens_seen': 3349856}\n",
            "100% 1000/1000 [26:34<00:00,  1.01it/s]\n",
            "100% 111/111 [10:27<00:00,  4.64s/it]\u001b[A\n",
            "{'train_runtime': 1595.2051, 'train_samples_per_second': 20.06, 'train_steps_per_second': 0.627, 'train_tokens_per_second': 5135.39, 'train_loss': 1.0620436935424804, 'epoch': 35.72, 'num_input_tokens_seen': 3349856}\n",
            "100% 1000/1000 [26:35<00:00,  1.60s/it]\n"
          ]
        }
      ],
      "source": [
        "!python train_lora.py \\\n",
        "    --model \"ai4bharat/indictrans2-en-indic-dist-200M\" \\\n",
        "    --src_lang_list \"eng_Latn\" \\\n",
        "    --tgt_lang_list \"tel_Telu\" \\\n",
        "    --data_dir \"/content/Scientific_Dataset_Parallel/en-indic-exp\" \\\n",
        "    --output_dir \"/content/fine_tuned_model_telugu\" \\\n",
        "    --save_steps 1000 \\\n",
        "    --max_steps 1000 \\\n",
        "    --batch_size 8 \\\n",
        "    --grad_accum_steps 4 \\\n",
        "    --warmup_steps 4000 \\\n",
        "    --max_grad_norm 1.0 \\\n",
        "    --learning_rate 2e-4 \\\n",
        "    --adam_beta1 0.9 \\\n",
        "    --adam_beta2 0.98 \\\n",
        "    --optimizer adamw_torch \\\n",
        "    --lr_scheduler inverse_sqrt \\\n",
        "    --num_workers 16 \\\n",
        "    --metric_for_best_model eval_BLEU \\\n",
        "    --greater_is_better \\\n",
        "    --patience 10 \\\n",
        "    --weight_decay 0.01 \\\n",
        "    --lora_target_modules \"q_proj,k_proj\" \\\n",
        "    --lora_dropout 0.1 \\\n",
        "    --lora_r 16 \\\n",
        "    --lora_alpha 32"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Specify the folder path and the desired name for the zip file\n",
        "folder_path = '/content/fine_tuned_model_telugu'  # Replace with your folder path\n",
        "zip_file_name = 'fine_tuned_model_telugu.zip'  # Replace with the desired zip file name\n",
        "\n",
        "# Create a zip file from the folder\n",
        "shutil.make_archive(zip_file_name[:-4], 'zip', folder_path)\n",
        "\n",
        "# Download the zip file\n",
        "files.download(zip_file_name)"
      ],
      "metadata": {
        "id": "5drCeTWnDkXD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "2d03c559-6a14-4e09-fcbf-afc3eb9204eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0a0b999e-6a54-44b2-b8bd-ebc53d2f622c\", \"fine_tuned_model_telugu.zip\", 26260690)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TOEZj-nhK9Ge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wgWxoJIkK9C8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v8tLzcukK9Ae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mIWXiMJ1K89m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GNV7YXJhK86s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iTm2wlC7K84E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwKjEfOOaTmf"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!git clone https://github.com/AI4Bharat/IndicTrans2.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxRMwcTIaTmf"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%cd /content/IndicTrans2/huggingface_interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORw8FZlZaTmg"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!python3 -m pip install nltk sacremoses pandas regex mock transformers>=4.33.2 mosestokenizer\n",
        "!python3 -c \"import nltk; nltk.download('punkt')\"\n",
        "!python3 -m pip install bitsandbytes scipy accelerate datasets\n",
        "!python3 -m pip install sentencepiece\n",
        "\n",
        "!git clone https://github.com/VarunGumma/IndicTransToolkit.git\n",
        "%cd IndicTransToolkit\n",
        "!python3 -m pip install --editable ./\n",
        "%cd ..\n",
        "\n",
        "#restart session"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scientific_sentences = [\n",
        "    \"In photosynthetic organisms, chlorophyll molecules embedded in the thylakoid membranes of chloroplasts absorb photons, initiating a series of redox reactions that ultimately produce ATP and NADPH, essential for the Calvin cycle.\",\n",
        "    \"The principle of quantum superposition states that, until measured, a particle such as an electron can exist simultaneously in multiple states, a phenomenon that underlies quantum computing and Schrödinger’s cat thought experiment.\",\n",
        "    \"Einstein’s general theory of relativity postulates that massive objects cause a distortion in spacetime, leading to gravitational effects that can bend light, slow down time, and even create black holes with event horizons from which no information can escape.\",\n",
        "    \"Mitochondrial DNA, inherited exclusively from the maternal lineage, plays a crucial role in cellular respiration by encoding essential components of the electron transport chain, which generates ATP through oxidative phosphorylation.\",\n",
        "    \"The Heisenberg uncertainty principle asserts that it is fundamentally impossible to simultaneously determine both the precise position and momentum of a subatomic particle, placing fundamental limits on measurement in quantum mechanics.\",\n",
        "    \"Thermodynamics dictates that entropy, a measure of disorder in a system, must always increase in a closed system over time, leading to the inevitable progression toward thermodynamic equilibrium as described by the second law of thermodynamics.\",\n",
        "    \"In ecological systems, trophic cascades occur when the removal or addition of a top predator disrupts population dynamics across multiple trophic levels, ultimately altering ecosystem stability and biodiversity.\",\n",
        "    \"During embryonic development, pluripotent stem cells undergo tightly regulated genetic and epigenetic modifications, leading to differentiation into specialized cell types such as neurons, muscle fibers, and epithelial cells.\",\n",
        "    \"Plate tectonic theory explains how the movement of Earth's lithospheric plates, driven by convective currents in the underlying mantle, results in the formation of mountain ranges, oceanic trenches, and seismic activity along fault lines.\",\n",
        "    \"Dark matter, an invisible and non-luminous component of the universe, is hypothesized to constitute approximately 27% of the cosmos, inferred primarily through its gravitational effects on galactic rotation curves and large-scale cosmic structures.\",\n",
        "    \"The double-helix structure of DNA, first elucidated by Watson and Crick, is stabilized by hydrogen bonds between complementary nitrogenous bases, ensuring accurate replication during the S phase of the cell cycle.\",\n",
        "    \"In astrophysics, the expansion of the universe, first observed by Edwin Hubble, is accelerating due to the mysterious influence of dark energy, a phenomenon that remains one of the greatest unsolved problems in modern cosmology.\",\n",
        "    \"Epigenetic modifications, including DNA methylation and histone acetylation, regulate gene expression without altering the underlying genetic code, playing critical roles in development, disease susceptibility, and cellular differentiation.\",\n",
        "    \"The CRISPR-Cas9 gene-editing technology utilizes a bacterial immune system mechanism to introduce targeted modifications in DNA sequences, revolutionizing genetic engineering and opening new possibilities for gene therapy.\",\n",
        "    \"Superconductors, when cooled below a critical temperature, exhibit zero electrical resistance and expel magnetic fields due to the Meissner effect, making them highly promising for applications in quantum computing and magnetic levitation.\",\n",
        "    \"In neuroscience, synaptic plasticity, particularly long-term potentiation (LTP), is considered a fundamental mechanism underlying learning and memory formation, involving the strengthening of synaptic connections through repeated stimulation.\",\n",
        "    \"The anthropic principle in cosmology suggests that the physical laws of the universe appear finely tuned to allow for the emergence of life, leading to philosophical debates regarding the possibility of multiple universes with varying fundamental constants.\",\n",
        "    \"The formation of complex organic molecules in prebiotic Earth, hypothesized in the Miller-Urey experiment, provides insights into the chemical pathways that may have led to the emergence of self-replicating molecules and the origins of life.\",\n",
        "    \"In particle physics, the discovery of the Higgs boson at CERN’s Large Hadron Collider confirmed the existence of the Higgs field, which imparts mass to elementary particles through spontaneous symmetry breaking.\",\n",
        "    \"Black hole thermodynamics, as described by Stephen Hawking, suggests that black holes emit Hawking radiation due to quantum effects near the event horizon, potentially leading to their eventual evaporation over cosmological timescales.\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "U2s5xE2yiiQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from peft import PeftModel\n",
        "from IndicTransToolkit import IndicProcessor\n",
        "\n",
        "# Load the base model\n",
        "base_ckpt_dir = \"ai4bharat/indictrans2-en-indic-dist-200M\"  # Change this as per your use case\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_ckpt_dir, trust_remote_code=True)\n",
        "base_model = AutoModelForSeq2SeqLM.from_pretrained(base_ckpt_dir, trust_remote_code=True)\n",
        "\n",
        "# Move the model to the appropriate device\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "base_model.to(DEVICE)\n",
        "\n",
        "# Test translation with your model\n",
        "input_sentences = scientific_sentences\n",
        "\n",
        "\n",
        "# Preprocess and translate\n",
        "src_lang, tgt_lang = \"eng_Latn\", \"tel_Telu\"  # Adjust target language as needed\n",
        "ip = IndicProcessor(inference=True)\n",
        "\n",
        "# Preprocess input sentences\n",
        "batch = ip.preprocess_batch(input_sentences, src_lang=src_lang, tgt_lang=tgt_lang)\n",
        "\n",
        "# Tokenize the sentences and generate input encodings\n",
        "inputs = tokenizer(\n",
        "    batch,\n",
        "    truncation=True,\n",
        "    padding=\"longest\",\n",
        "    return_tensors=\"pt\",\n",
        ").to(DEVICE)  # Move inputs to the same device as the model\n",
        "\n",
        "# Generate translations using the model\n",
        "with torch.no_grad():\n",
        "    generated_tokens = base_model.generate(\n",
        "        **inputs,\n",
        "        use_cache=True,\n",
        "        min_length=0,\n",
        "        max_length=256,\n",
        "        num_beams=5,\n",
        "        num_return_sequences=1,\n",
        "    )\n",
        "\n",
        "# Decode the generated tokens into text\n",
        "with tokenizer.as_target_tokenizer():\n",
        "    generated_tokens = tokenizer.batch_decode(\n",
        "        generated_tokens.detach().cpu().tolist(),\n",
        "        skip_special_tokens=True,\n",
        "        clean_up_tokenization_spaces=True,\n",
        "    )\n",
        "\n",
        "# Postprocess the translations\n",
        "translations = ip.postprocess_batch(generated_tokens, lang=tgt_lang)\n",
        "\n",
        "# Print the results\n",
        "for input_sentence, translation in zip(input_sentences, translations):\n",
        "    print(f\"Source: {input_sentence}\")\n",
        "    print(f\"Translation: {translation}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHhyK0c7gZ2T",
        "outputId": "68b7b92f-6091-442a-ba6e-4a235f240c72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source: In photosynthetic organisms, chlorophyll molecules embedded in the thylakoid membranes of chloroplasts absorb photons, initiating a series of redox reactions that ultimately produce ATP and NADPH, essential for the Calvin cycle.\n",
            "Translation: కిరణజన్య జీవులలో, క్లోరోప్లాస్ట్ల యొక్క థైలకాయిడ్ పొరల్లో పొందుపరచబడిన క్లోరోఫిల్ అణువులు ఫోటాన్లను గ్రహిస్తాయి, ఇవి కాల్విన్ చక్రానికి అవసరమైన ATP మరియు NADPHలను ఉత్పత్తి చేసే రెడాక్స్ ప్రతిచర్యల శ్రేణిని ప్రారంభిస్తాయి. \n",
            "\n",
            "Source: The principle of quantum superposition states that, until measured, a particle such as an electron can exist simultaneously in multiple states, a phenomenon that underlies quantum computing and Schrödinger’s cat thought experiment.\n",
            "Translation: క్వాంటం సూపర్పోసిషన్ సూత్రం ప్రకారం, కొలిచే వరకు, ఎలక్ట్రాన్ వంటి కణాలు ఏకకాలంలో బహుళ స్థితులలో ఉండగలవు, ఇది క్వాంటం కంప్యూటింగ్ మరియు ష్రోడింగర్ యొక్క పిల్లి ఆలోచన ప్రయోగానికి ఆధారం. \n",
            "\n",
            "Source: Einstein’s general theory of relativity postulates that massive objects cause a distortion in spacetime, leading to gravitational effects that can bend light, slow down time, and even create black holes with event horizons from which no information can escape.\n",
            "Translation: ఐన్స్టీన్ యొక్క సాధారణ సాపేక్షత సిద్ధాంతం భారీ వస్తువులు అంతరిక్ష సమయంలో వక్రీకరణకు కారణమవుతాయని, ఇవి గురుత్వాకర్షణ ప్రభావాలకు దారితీస్తాయని, ఇవి కాంతిని వంచగలవని, సమయాన్ని మందగించగలవని, మరియు ఎటువంటి సమాచారం తప్పించుకోలేని సంఘటన పరిధులతో కాల రంధ్రాలను కూడా సృష్టించగలవని పేర్కొంది. \n",
            "\n",
            "Source: Mitochondrial DNA, inherited exclusively from the maternal lineage, plays a crucial role in cellular respiration by encoding essential components of the electron transport chain, which generates ATP through oxidative phosphorylation.\n",
            "Translation: తల్లి వంశం నుండి ప్రత్యేకంగా వారసత్వంగా వచ్చిన మైటోకాన్డ్రియల్ DNA, ఎలక్ట్రాన్ రవాణా గొలుసు యొక్క అవసరమైన భాగాలను ఎన్కోడింగ్ చేయడం ద్వారా సెల్యులార్ శ్వాసక్రియలో కీలక పాత్ర పోషిస్తుంది, ఇది ఆక్సీకరణ ఫాస్ఫోరైలేషన్ ద్వారా ATPని ఉత్పత్తి చేస్తుంది. \n",
            "\n",
            "Source: The Heisenberg uncertainty principle asserts that it is fundamentally impossible to simultaneously determine both the precise position and momentum of a subatomic particle, placing fundamental limits on measurement in quantum mechanics.\n",
            "Translation: హైసెన్బర్గ్ అనిశ్చితి సూత్రం క్వాంటం మెకానిక్స్లో కొలతపై ప్రాథమిక పరిమితులను ఉంచుతూ, ఉప పరమాణు కణం యొక్క ఖచ్చితమైన స్థానం మరియు మొమెంటం రెండింటినీ ఏకకాలంలో నిర్ణయించడం ప్రాథమికంగా అసాధ్యం అని నొక్కి చెబుతుంది. \n",
            "\n",
            "Source: Thermodynamics dictates that entropy, a measure of disorder in a system, must always increase in a closed system over time, leading to the inevitable progression toward thermodynamic equilibrium as described by the second law of thermodynamics.\n",
            "Translation: థర్మోడైనమిక్స్ యొక్క రెండవ చట్టం వివరించిన విధంగా థర్మోడైనమిక్ సమతౌల్యం వైపు అనివార్యమైన పురోగతికి దారితీసే విధంగా, ఒక వ్యవస్థలో రుగ్మత యొక్క కొలత అయిన ఎంట్రోపీ ఎల్లప్పుడూ కాలక్రమేణా క్లోజ్డ్ సిస్టమ్లో పెరగాలని థర్మోడైనమిక్స్ నిర్దేశిస్తుంది. \n",
            "\n",
            "Source: In ecological systems, trophic cascades occur when the removal or addition of a top predator disrupts population dynamics across multiple trophic levels, ultimately altering ecosystem stability and biodiversity.\n",
            "Translation: పర్యావరణ వ్యవస్థలలో, అగ్రశ్రేణి ప్రెడేటర్ను తొలగించడం లేదా జోడించడం అనేది బహుళ ట్రోఫిక్ స్థాయిలలో జనాభా గతిశీలతకు అంతరాయం కలిగించినప్పుడు, చివరికి పర్యావరణ వ్యవస్థ స్థిరత్వం మరియు జీవవైవిధ్యాన్ని మార్చినప్పుడు ట్రోఫిక్ క్యాస్కేడ్లు సంభవిస్తాయి. \n",
            "\n",
            "Source: During embryonic development, pluripotent stem cells undergo tightly regulated genetic and epigenetic modifications, leading to differentiation into specialized cell types such as neurons, muscle fibers, and epithelial cells.\n",
            "Translation: పిండం అభివృద్ధి సమయంలో, ప్లురిపోటెంట్ మూల కణాలు కఠినంగా నియంత్రించబడే జన్యు మరియు ఎపిజెనెటిక్ మార్పులకు లోనవుతాయి, ఇది న్యూరాన్లు, కండరాల ఫైబర్స్ మరియు ఎపిథీలియల్ కణాలు వంటి ప్రత్యేక కణ రకాలుగా భేదానికి దారితీస్తుంది. \n",
            "\n",
            "Source: Plate tectonic theory explains how the movement of Earth's lithospheric plates, driven by convective currents in the underlying mantle, results in the formation of mountain ranges, oceanic trenches, and seismic activity along fault lines.\n",
            "Translation: అంతర్లీన మాంటిల్లోని ఉష్ణప్రసరణ ప్రవాహాల ద్వారా నడిచే భూమి యొక్క లితో ఆవరణ ఫలకాల కదలిక, పర్వత శ్రేణులు, సముద్ర కందకాలు మరియు లోపం రేఖల వెంట భూకంప కార్యకలాపాలకు ఎలా దారితీస్తుందో ప్లేట్ టెక్టోనిక్ సిద్ధాంతం వివరిస్తుంది. \n",
            "\n",
            "Source: Dark matter, an invisible and non-luminous component of the universe, is hypothesized to constitute approximately 27% of the cosmos, inferred primarily through its gravitational effects on galactic rotation curves and large-scale cosmic structures.\n",
            "Translation: విశ్వం యొక్క అదృశ్య మరియు ప్రకాశించని భాగం అయిన కృష్ణ పదార్థం, విశ్వంలో సుమారు 27 శాతం ఉంటుందని ఊహించబడింది, ప్రధానంగా గెలాక్సీ భ్రమణ వక్రతలు మరియు పెద్ద ఎత్తున విశ్వ నిర్మాణాలపై దాని గురుత్వాకర్షణ ప్రభావాల ద్వారా ఊహించబడింది. \n",
            "\n",
            "Source: The double-helix structure of DNA, first elucidated by Watson and Crick, is stabilized by hydrogen bonds between complementary nitrogenous bases, ensuring accurate replication during the S phase of the cell cycle.\n",
            "Translation: వాట్సన్ మరియు క్రిక్ మొదట స్పష్టం చేసిన DNA యొక్క డబుల్-హెలిక్స్ నిర్మాణం, పూరక నత్రజని స్థావరాల మధ్య హైడ్రోజన్ బంధాల ద్వారా స్థిరీకరించబడుతుంది, ఇది కణ చక్రం యొక్క S దశలో ఖచ్చితమైన ప్రతిరూపణను నిర్ధారిస్తుంది. \n",
            "\n",
            "Source: In astrophysics, the expansion of the universe, first observed by Edwin Hubble, is accelerating due to the mysterious influence of dark energy, a phenomenon that remains one of the greatest unsolved problems in modern cosmology.\n",
            "Translation: ఖగోళ భౌతిక శాస్త్రంలో, ఎడ్విన్ హబుల్ మొదటిసారిగా గమనించిన విశ్వం యొక్క విస్తరణ, డార్క్ ఎనర్జీ యొక్క మర్మమైన ప్రభావం కారణంగా వేగవంతం అవుతోంది, ఈ దృగ్విషయం ఆధునిక విశ్వోద్భవ శాస్త్రంలో పరిష్కరించని అతిపెద్ద సమస్యలలో ఒకటిగా మిగిలిపోయింది. \n",
            "\n",
            "Source: Epigenetic modifications, including DNA methylation and histone acetylation, regulate gene expression without altering the underlying genetic code, playing critical roles in development, disease susceptibility, and cellular differentiation.\n",
            "Translation: DNA మిథైలేషన్ మరియు హిస్టోన్ అసిటైలేషన్తో సహా ఎపిజెనెటిక్ మార్పులు, అంతర్లీన జన్యు సంకేతాన్ని మార్చకుండా జన్యు వ్యక్తీకరణను నియంత్రిస్తాయి, అభివృద్ధి, వ్యాధి గ్రహణశీలత మరియు సెల్యులార్ భేదంలో కీలక పాత్రలు పోషిస్తాయి. \n",
            "\n",
            "Source: The CRISPR-Cas9 gene-editing technology utilizes a bacterial immune system mechanism to introduce targeted modifications in DNA sequences, revolutionizing genetic engineering and opening new possibilities for gene therapy.\n",
            "Translation: CRISPR-Cas9 జన్యు-సవరణ సాంకేతికత DNA శ్రేణులలో లక్ష్య మార్పులను ప్రవేశపెట్టడానికి, జన్యు ఇంజనీరింగ్లో విప్లవాత్మక మార్పులు చేయడానికి మరియు జన్యు చికిత్సకు కొత్త అవకాశాలను తెరవడానికి బ్యాక్టీరియా రోగనిరోధక వ్యవస్థ యంత్రాంగాన్ని ఉపయోగిస్తుంది. \n",
            "\n",
            "Source: Superconductors, when cooled below a critical temperature, exhibit zero electrical resistance and expel magnetic fields due to the Meissner effect, making them highly promising for applications in quantum computing and magnetic levitation.\n",
            "Translation: సూపర్ కండక్టర్లు, క్లిష్టమైన ఉష్ణోగ్రత కంటే తక్కువగా చల్లబడినప్పుడు, సున్నా విద్యుత్ నిరోధకతను ప్రదర్శిస్తాయి మరియు మీస్నర్ ప్రభావం కారణంగా అయస్కాంత క్షేత్రాలను బహిష్కరిస్తాయి, ఇవి క్వాంటం కంప్యూటింగ్ మరియు అయస్కాంత లెవిటేషన్లో అనువర్తనాలకు చాలా ఆశాజనకంగా ఉంటాయి. \n",
            "\n",
            "Source: In neuroscience, synaptic plasticity, particularly long-term potentiation (LTP), is considered a fundamental mechanism underlying learning and memory formation, involving the strengthening of synaptic connections through repeated stimulation.\n",
            "Translation: న్యూరోసైన్స్లో, సినాప్టిక్ ప్లాస్టిసిటీ, ముఖ్యంగా దీర్ఘకాలిక పొటెన్షియేషన్ (ఎల్టిపి), నేర్చుకోవడం మరియు జ్ఞాపకశక్తి ఏర్పడటానికి అంతర్లీనంగా ఉన్న ప్రాథమిక యంత్రాంగంగా పరిగణించబడుతుంది, ఇందులో పునరావృత ఉద్దీపన ద్వారా సినాప్టిక్ కనెక్షన్లను బలోపేతం చేయడం ఉంటుంది. \n",
            "\n",
            "Source: The anthropic principle in cosmology suggests that the physical laws of the universe appear finely tuned to allow for the emergence of life, leading to philosophical debates regarding the possibility of multiple universes with varying fundamental constants.\n",
            "Translation: విశ్వోద్భవ శాస్త్రంలోని మానవశాస్త్ర సూత్రం విశ్వం యొక్క భౌతిక నియమాలు జీవుల ఆవిర్భావాన్ని అనుమతించడానికి చక్కగా ట్యూన్ చేయబడినట్లు కనిపిస్తాయని సూచిస్తుంది, ఇది వివిధ ప్రాథమిక స్థిరాంకాలతో బహుళ విశ్వాల సంభావ్యత గురించి తాత్విక చర్చలకు దారితీస్తుంది. \n",
            "\n",
            "Source: The formation of complex organic molecules in prebiotic Earth, hypothesized in the Miller-Urey experiment, provides insights into the chemical pathways that may have led to the emergence of self-replicating molecules and the origins of life.\n",
            "Translation: మిల్లర్-యూరే ప్రయోగంలో ఊహించిన ప్రీబయోటిక్ భూమిలో సంక్లిష్ట సేంద్రీయ అణువుల నిర్మాణం, స్వీయ-ప్రతిరూపణ అణువుల ఆవిర్భావానికి మరియు జీవితం యొక్క మూలాలకు దారితీసిన రసాయన మార్గాలపై అంతర్దృష్టులను అందిస్తుంది. \n",
            "\n",
            "Source: In particle physics, the discovery of the Higgs boson at CERN’s Large Hadron Collider confirmed the existence of the Higgs field, which imparts mass to elementary particles through spontaneous symmetry breaking.\n",
            "Translation: కణ భౌతిక శాస్త్రంలో, CERN యొక్క లార్జ్ హాడ్రాన్ కొలైడర్ వద్ద హిగ్స్ బోసన్ ఆవిష్కరణ హిగ్స్ క్షేత్రం ఉనికిని ధృవీకరించింది, ఇది ఆకస్మిక సమరూపత విచ్ఛిన్నం ద్వారా ప్రాథమిక కణాలకు ద్రవ్యరాశిని అందిస్తుంది. \n",
            "\n",
            "Source: Black hole thermodynamics, as described by Stephen Hawking, suggests that black holes emit Hawking radiation due to quantum effects near the event horizon, potentially leading to their eventual evaporation over cosmological timescales.\n",
            "Translation: స్టీఫెన్ హాకింగ్ వర్ణించిన బ్లాక్ హోల్ థర్మోడైనమిక్స్, ఈవెంట్ హోరిజోన్ సమీపంలో క్వాంటం ప్రభావాల కారణంగా బ్లాక్ హోల్స్ హాకింగ్ రేడియేషన్ను విడుదల చేస్తాయని సూచిస్తుంది, ఇది కాస్మోలాజికల్ టైమ్స్కేల్పై వాటి చివరికి ఆవిరికి దారితీస్తుంది. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to the zip file\n",
        "zip_file_path = '/content/fine_tuned_model_telugu_Scientific_dataset.zip'\n",
        "\n",
        "# Path to extract the files\n",
        "extract_to_path = '/content/fine_tuned_model_telugu'\n",
        "\n",
        "# Create the extraction directory if it doesn't exist\n",
        "os.makedirs(extract_to_path, exist_ok=True)\n",
        "\n",
        "# Unzipping the folder\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to_path)\n",
        "\n",
        "print(f\"Files have been unzipped to: {extract_to_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaViD6jNhNPy",
        "outputId": "47eda86d-b77a-4a74-e2c7-5ef4fe77d5ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files have been unzipped to: /content/fine_tuned_model_telugu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from peft import PeftModel\n",
        "from IndicTransToolkit import IndicProcessor\n",
        "\n",
        "# Load the base model\n",
        "base_ckpt_dir = \"ai4bharat/indictrans2-en-indic-dist-200M\"  # Change this as per your use case\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_ckpt_dir, trust_remote_code=True)\n",
        "base_model = AutoModelForSeq2SeqLM.from_pretrained(base_ckpt_dir, trust_remote_code=True)\n",
        "\n",
        "# Load the LoRA model\n",
        "lora_ckpt_dir = \"/content/fine_tuned_model_telugu\"  # Path to your fine-tuned model directory\n",
        "lora_model = PeftModel.from_pretrained(base_model, lora_ckpt_dir)\n",
        "\n",
        "# Move the model to the appropriate device\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "lora_model.to(DEVICE)\n",
        "\n",
        "# Test translation with your model\n",
        "input_sentences = scientific_sentences\n",
        "\n",
        "# Preprocess and translate\n",
        "src_lang, tgt_lang = \"eng_Latn\", \"tel_Telu\"  # Adjust target language as needed\n",
        "ip = IndicProcessor(inference=True)\n",
        "\n",
        "# Preprocess input sentences\n",
        "batch = ip.preprocess_batch(input_sentences, src_lang=src_lang, tgt_lang=tgt_lang)\n",
        "\n",
        "# Tokenize the sentences and generate input encodings\n",
        "inputs = tokenizer(\n",
        "    batch,\n",
        "    truncation=True,\n",
        "    padding=\"longest\",\n",
        "    return_tensors=\"pt\",\n",
        ").to(DEVICE)  # Move inputs to the same device as the model\n",
        "\n",
        "# Generate translations using the model\n",
        "with torch.no_grad():\n",
        "    generated_tokens = lora_model.generate(\n",
        "        **inputs,\n",
        "        use_cache=True,\n",
        "        min_length=0,\n",
        "        max_length=256,\n",
        "        num_beams=5,\n",
        "        num_return_sequences=1,\n",
        "    )\n",
        "\n",
        "# Decode the generated tokens into text\n",
        "with tokenizer.as_target_tokenizer():\n",
        "    generated_tokens = tokenizer.batch_decode(\n",
        "        generated_tokens.detach().cpu().tolist(),\n",
        "        skip_special_tokens=True,\n",
        "        clean_up_tokenization_spaces=True,\n",
        "    )\n",
        "\n",
        "# Postprocess the translations\n",
        "translations = ip.postprocess_batch(generated_tokens, lang=tgt_lang)\n",
        "\n",
        "# Print the results\n",
        "for input_sentence, translation in zip(input_sentences, translations):\n",
        "    print(f\"Source: {input_sentence}\")\n",
        "    print(f\"Translation: {translation}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuEwFDEngatE",
        "outputId": "3f9f246c-960a-4a32-d690-fe3c4b998ff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source: In photosynthetic organisms, chlorophyll molecules embedded in the thylakoid membranes of chloroplasts absorb photons, initiating a series of redox reactions that ultimately produce ATP and NADPH, essential for the Calvin cycle.\n",
            "Translation: కిరణజన్య జీవులలో, క్లోరోప్లాస్ట్ల థైలకాయిడ్ పొరల్లో పొందుపరచబడిన క్లోరోఫిల్ అణువులు ఫోటాన్లను గ్రహిస్తాయి, ఇవి కాల్విన్ చక్రానికి అవసరమైన ATP మరియు NADPHలను ఉత్పత్తి చేసే రెడాక్స్ ప్రతిచర్యల శ్రేణిని ప్రారంభిస్తాయి. \n",
            "\n",
            "Source: The principle of quantum superposition states that, until measured, a particle such as an electron can exist simultaneously in multiple states, a phenomenon that underlies quantum computing and Schrödinger’s cat thought experiment.\n",
            "Translation: క్వాంటం సూపర్పోసిషన్ సూత్రం ప్రకారం, కొలిచే వరకు, ఎలక్ట్రాన్ వంటి ఒక కణం ఒకేసారి బహుళ స్థితులలో ఉండగలదు, ఇది క్వాంటం కంప్యూటింగ్ మరియు ష్రోడింగర్ యొక్క పిల్లి ఆలోచనా ప్రయోగానికి ఆధారం. \n",
            "\n",
            "Source: Einstein’s general theory of relativity postulates that massive objects cause a distortion in spacetime, leading to gravitational effects that can bend light, slow down time, and even create black holes with event horizons from which no information can escape.\n",
            "Translation: ఐన్స్టీన్ యొక్క సాధారణ సాపేక్షత సిద్ధాంతం ప్రకారం, భారీ వస్తువులు అంతరిక్ష సమయంలో వక్రీకరణకు కారణమవుతాయి, ఇవి గురుత్వాకర్షణ ప్రభావాలకు దారితీస్తాయి, ఇవి కాంతిని వంచగలవు, సమయాన్ని మందగించగలవు మరియు సంఘటన పరిధులతో కాల రంధ్రాలను కూడా సృష్టించగలవు, వీటి నుండి ఎటువంటి సమాచారం తప్పించుకోలేము. \n",
            "\n",
            "Source: Mitochondrial DNA, inherited exclusively from the maternal lineage, plays a crucial role in cellular respiration by encoding essential components of the electron transport chain, which generates ATP through oxidative phosphorylation.\n",
            "Translation: తల్లి వంశం నుండి ప్రత్యేకంగా వారసత్వంగా వచ్చిన మైటోకాన్డ్రియల్ DNA, ఎలక్ట్రాన్ రవాణా గొలుసు యొక్క ముఖ్యమైన భాగాలను ఎన్కోడ్ చేయడం ద్వారా సెల్యులార్ శ్వాసక్రియలో కీలక పాత్ర పోషిస్తుంది, ఇది ఆక్సీకరణ ఫాస్ఫోరైలేషన్ ద్వారా ATPని ఉత్పత్తి చేస్తుంది. \n",
            "\n",
            "Source: The Heisenberg uncertainty principle asserts that it is fundamentally impossible to simultaneously determine both the precise position and momentum of a subatomic particle, placing fundamental limits on measurement in quantum mechanics.\n",
            "Translation: క్వాంటం మెకానిక్స్లో కొలతపై ప్రాథమిక పరిమితులను ఉంచుతూ, ఉప పరమాణు కణం యొక్క ఖచ్చితమైన స్థానం మరియు మొమెంటం రెండింటినీ ఏకకాలంలో నిర్ణయించడం ప్రాథమికంగా అసాధ్యం అని హైసెన్బర్గ్ అనిశ్చితి సూత్రం నొక్కి చెబుతోంది. \n",
            "\n",
            "Source: Thermodynamics dictates that entropy, a measure of disorder in a system, must always increase in a closed system over time, leading to the inevitable progression toward thermodynamic equilibrium as described by the second law of thermodynamics.\n",
            "Translation: థర్మోడైనమిక్స్ ప్రకారం, ఒక వ్యవస్థలో క్రమరాహిత్యం యొక్క కొలత అయిన ఎంట్రోపీ, కాలక్రమేణా క్లోజ్డ్ సిస్టమ్లో ఎల్లప్పుడూ పెరగాలి, ఇది థర్మోడైనమిక్స్ రెండవ చట్టం ద్వారా వివరించబడిన విధంగా థర్మోడైనమిక్ సమతౌల్యం వైపు అనివార్యమైన పురోగతికి దారితీస్తుంది. \n",
            "\n",
            "Source: In ecological systems, trophic cascades occur when the removal or addition of a top predator disrupts population dynamics across multiple trophic levels, ultimately altering ecosystem stability and biodiversity.\n",
            "Translation: పర్యావరణ వ్యవస్థలలో, అగ్రశ్రేణి మాంసాహారిని తొలగించడం లేదా కలపడం వల్ల బహుళ పోషక స్థాయిలలో జనాభా గతిశీలత దెబ్బతిన్నప్పుడు, చివరికి పర్యావరణ వ్యవస్థ స్థిరత్వం మరియు జీవవైవిధ్యాన్ని మార్చినప్పుడు పోషక ప్రవాహాలు ఏర్పడతాయి. \n",
            "\n",
            "Source: During embryonic development, pluripotent stem cells undergo tightly regulated genetic and epigenetic modifications, leading to differentiation into specialized cell types such as neurons, muscle fibers, and epithelial cells.\n",
            "Translation: పిండం అభివృద్ధి సమయంలో, ప్లురిపోటెంట్ స్టెమ్ సెల్స్ కఠినంగా నియంత్రించబడే జన్యు మరియు ఎపిజెనెటిక్ మార్పులకు లోనవుతాయి, ఇది న్యూరాన్లు, కండరాల ఫైబర్స్ మరియు ఎపిథీలియల్ సెల్స్ వంటి ప్రత్యేక కణాల రకాలుగా తేడాకు దారితీస్తుంది. \n",
            "\n",
            "Source: Plate tectonic theory explains how the movement of Earth's lithospheric plates, driven by convective currents in the underlying mantle, results in the formation of mountain ranges, oceanic trenches, and seismic activity along fault lines.\n",
            "Translation: భూమి యొక్క శిలాస్థల ఫలకాల కదలిక, అంతర్లీన ఆవరణలోని ఉష్ణప్రసరణ ప్రవాహాల ద్వారా ఎలా నడుపబడుతుందో ప్లేట్ టెక్టోనిక్ సిద్ధాంతం వివరిస్తుంది, దీని ఫలితంగా పర్వత శ్రేణులు, సముద్రపు కందకాలు మరియు భూకంపాల కార్యకలాపాలు ఏర్పడతాయి. \n",
            "\n",
            "Source: Dark matter, an invisible and non-luminous component of the universe, is hypothesized to constitute approximately 27% of the cosmos, inferred primarily through its gravitational effects on galactic rotation curves and large-scale cosmic structures.\n",
            "Translation: విశ్వంలో ఒక అదృశ్య మరియు ప్రకాశించని భాగం అయిన కృష్ణ పదార్థం, విశ్వంలో సుమారు 27 శాతం ఉంటుందని ఊహించబడింది, ఇది ప్రధానంగా గెలాక్సీ భ్రమణ వక్రతలు మరియు పెద్ద ఎత్తున విశ్వ నిర్మాణాలపై దాని గురుత్వాకర్షణ ప్రభావాల ద్వారా అంచనా వేయబడింది. \n",
            "\n",
            "Source: The double-helix structure of DNA, first elucidated by Watson and Crick, is stabilized by hydrogen bonds between complementary nitrogenous bases, ensuring accurate replication during the S phase of the cell cycle.\n",
            "Translation: వాట్సన్ మరియు క్రిక్ ద్వారా మొదట వివరించబడిన DNA యొక్క డబుల్-హెలిక్స్ నిర్మాణం, కణ చక్రం యొక్క S దశలో ఖచ్చితమైన ప్రతిరూపణను నిర్ధారిస్తూ, పరిపూరకరమైన నత్రజని స్థావరాల మధ్య హైడ్రోజన్ బంధాల ద్వారా స్థిరీకరించబడుతుంది. \n",
            "\n",
            "Source: In astrophysics, the expansion of the universe, first observed by Edwin Hubble, is accelerating due to the mysterious influence of dark energy, a phenomenon that remains one of the greatest unsolved problems in modern cosmology.\n",
            "Translation: ఖగోళ భౌతిక శాస్త్రంలో, ఎడ్విన్ హబుల్ మొదటిసారిగా గమనించిన విశ్వం యొక్క విస్తరణ, ఆధునిక విశ్వోద్భవ శాస్త్రంలో పరిష్కరించబడని అతిపెద్ద సమస్యలలో ఒకటిగా మిగిలిపోయిన చీకటి శక్తి యొక్క మర్మమైన ప్రభావం కారణంగా వేగవంతం అవుతోంది. \n",
            "\n",
            "Source: Epigenetic modifications, including DNA methylation and histone acetylation, regulate gene expression without altering the underlying genetic code, playing critical roles in development, disease susceptibility, and cellular differentiation.\n",
            "Translation: DNA మిథైలేషన్ మరియు హిస్టోన్ ఎసిటైలేషన్తో సహా ఎపిజెనెటిక్ మార్పులు, అంతర్లీన జన్యు సంకేతాన్ని మార్చకుండా జన్యు వ్యక్తీకరణను నియంత్రిస్తాయి, అభివృద్ధి, వ్యాధి వ్యాప్తి మరియు సెల్యులార్ భేదంలో కీలక పాత్రలు పోషిస్తాయి. \n",
            "\n",
            "Source: The CRISPR-Cas9 gene-editing technology utilizes a bacterial immune system mechanism to introduce targeted modifications in DNA sequences, revolutionizing genetic engineering and opening new possibilities for gene therapy.\n",
            "Translation: CRISPR-Cas9 జన్యు-సవరణ సాంకేతికత DNA శ్రేణులలో లక్ష్య మార్పులను ప్రవేశపెట్టడానికి, జన్యు ఇంజనీరింగ్లో విప్లవాత్మక మార్పులు తీసుకురావడానికి మరియు జన్యు చికిత్సకు కొత్త అవకాశాలను తెరవడానికి బ్యాక్టీరియా రోగనిరోధక వ్యవస్థ యంత్రాంగాన్ని ఉపయోగిస్తుంది. \n",
            "\n",
            "Source: Superconductors, when cooled below a critical temperature, exhibit zero electrical resistance and expel magnetic fields due to the Meissner effect, making them highly promising for applications in quantum computing and magnetic levitation.\n",
            "Translation: సూపర్ కండక్టర్లను క్లిష్టమైన ఉష్ణోగ్రత కంటే తక్కువగా చల్లబరచినప్పుడు, అవి సున్నా విద్యుత్ నిరోధకతను ప్రదర్శిస్తాయి మరియు మైస్నర్ ప్రభావం కారణంగా అయస్కాంత క్షేత్రాలను బహిష్కరిస్తాయి, ఇవి క్వాంటం కంప్యూటింగ్ మరియు అయస్కాంత లెవిటేషన్లలో అనువర్తనాలకు చాలా ఆశాజనకంగా ఉంటాయి. \n",
            "\n",
            "Source: In neuroscience, synaptic plasticity, particularly long-term potentiation (LTP), is considered a fundamental mechanism underlying learning and memory formation, involving the strengthening of synaptic connections through repeated stimulation.\n",
            "Translation: న్యూరోసైన్స్లో, సినాప్టిక్ ప్లాస్టిసిటీ, ముఖ్యంగా దీర్ఘకాలిక పొటెన్షియేషన్ (LTP), నేర్చుకోవడం మరియు జ్ఞాపకశక్తి ఏర్పడటానికి అంతర్లీనంగా ఉండే ఒక ప్రాథమిక యంత్రాంగంగా పరిగణించబడుతుంది, ఇందులో పునరావృత ఉద్దీపన ద్వారా సినాప్టిక్ కనెక్షన్లను బలోపేతం చేయడం ఉంటుంది. \n",
            "\n",
            "Source: The anthropic principle in cosmology suggests that the physical laws of the universe appear finely tuned to allow for the emergence of life, leading to philosophical debates regarding the possibility of multiple universes with varying fundamental constants.\n",
            "Translation: విశ్వోద్భవ శాస్త్రంలోని మానవశాస్త్ర సూత్రం ప్రకారం, విశ్వం యొక్క భౌతిక నియమాలు జీవితం ఉద్భవించడానికి చక్కగా అనుగుణంగా కనిపిస్తాయి, ఇది వివిధ ప్రాథమిక స్థిరాంకాలతో బహుళ విశ్వాల సంభావ్యత గురించి తాత్విక చర్చలకు దారితీస్తుంది. \n",
            "\n",
            "Source: The formation of complex organic molecules in prebiotic Earth, hypothesized in the Miller-Urey experiment, provides insights into the chemical pathways that may have led to the emergence of self-replicating molecules and the origins of life.\n",
            "Translation: మిల్లర్-యూరే ప్రయోగంలో ఊహించిన విధంగా, ప్రీబయోటిక్ భూమిలో సంక్లిష్టమైన సేంద్రియ అణువుల నిర్మాణం, స్వీయ-ప్రతిరూపణ అణువుల ఆవిర్భావానికి మరియు జీవ మూలాలకు దారితీసిన రసాయన మార్గాల గురించి అంతర్దృష్టులను అందిస్తుంది. \n",
            "\n",
            "Source: In particle physics, the discovery of the Higgs boson at CERN’s Large Hadron Collider confirmed the existence of the Higgs field, which imparts mass to elementary particles through spontaneous symmetry breaking.\n",
            "Translation: కణ భౌతిక శాస్త్రంలో, CERN యొక్క లార్జ్ హాడ్రోన్ కొలైడర్ వద్ద హిగ్స్ బోసన్ ఆవిష్కరణ హిగ్స్ క్షేత్రం ఉనికిని ధృవీకరించింది, ఇది సహజమైన సమరూపత విచ్ఛిన్నం ద్వారా ప్రాథమిక కణాలకు ద్రవ్యరాశిని అందిస్తుంది. \n",
            "\n",
            "Source: Black hole thermodynamics, as described by Stephen Hawking, suggests that black holes emit Hawking radiation due to quantum effects near the event horizon, potentially leading to their eventual evaporation over cosmological timescales.\n",
            "Translation: బ్లాక్ హోల్ థర్మోడైనమిక్స్, స్టీఫెన్ హాకింగ్ వివరించినట్లుగా, బ్లాక్ హోల్స్ ఈవెంట్ హోరిజోన్ సమీపంలో క్వాంటం ప్రభావాల కారణంగా హాకింగ్ రేడియేషన్ను విడుదల చేస్తాయని సూచిస్తుంది, ఇది విశ్వోద్భవ కాలక్రమాలపై వాటి చివరికి ఆవిరికి దారితీస్తుంది. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IVNdmLPdLK_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ffoKlpL2LK8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scientific_sentences = [\n",
        "    \"Photosynthesis converts light energy into chemical energy in plants.\",\n",
        "    \"DNA replication ensures genetic information is accurately passed to daughter cells.\",\n",
        "    \"The mitochondrion is the powerhouse of the cell, generating ATP through cellular respiration.\",\n",
        "    \"Newton's third law states that every action has an equal and opposite reaction.\",\n",
        "    \"The periodic table organizes elements based on atomic number and chemical properties.\",\n",
        "    \"Water has a high specific heat capacity, which helps regulate Earth's climate.\",\n",
        "    \"Enzymes act as biological catalysts to speed up chemical reactions in living organisms.\",\n",
        "    \"The Doppler effect explains the change in frequency of waves relative to an observer's motion.\",\n",
        "    \"Einstein's theory of relativity describes how time and space are interconnected.\",\n",
        "    \"The pH scale measures the acidity or alkalinity of a solution based on hydrogen ion concentration.\",\n",
        "    \"Black holes have gravitational fields so strong that nothing, not even light, can escape them.\",\n",
        "    \"Electrons orbit the nucleus of an atom in discrete energy levels.\",\n",
        "    \"Genetic mutations can lead to variations in traits and may contribute to evolution.\",\n",
        "    \"Ohm's law states that voltage equals current times resistance (V = IR).\",\n",
        "    \"Plate tectonics explains the movement of Earth's lithospheric plates over the mantle.\",\n",
        "    \"Chlorophyll is the pigment responsible for capturing light energy in photosynthesis.\",\n",
        "    \"The speed of light in a vacuum is approximately 299,792,458 meters per second.\",\n",
        "    \"Gravity is the force that attracts objects with mass toward each other.\",\n",
        "    \"The conservation of mass states that mass cannot be created or destroyed in a chemical reaction.\",\n",
        "    \"Quantum mechanics describes the behavior of particles on an atomic and subatomic scale.\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "I-QnaYZ-LKre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from peft import PeftModel\n",
        "from IndicTransToolkit import IndicProcessor\n",
        "\n",
        "# Load the base model\n",
        "base_ckpt_dir = \"ai4bharat/indictrans2-en-indic-dist-200M\"  # Change this as per your use case\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_ckpt_dir, trust_remote_code=True)\n",
        "base_model = AutoModelForSeq2SeqLM.from_pretrained(base_ckpt_dir, trust_remote_code=True)\n",
        "\n",
        "# Move the model to the appropriate device\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "base_model.to(DEVICE)\n",
        "\n",
        "# Test translation with your model\n",
        "input_sentences = scientific_sentences\n",
        "\n",
        "\n",
        "# Preprocess and translate\n",
        "src_lang, tgt_lang = \"eng_Latn\", \"tel_Telu\"  # Adjust target language as needed\n",
        "ip = IndicProcessor(inference=True)\n",
        "\n",
        "# Preprocess input sentences\n",
        "batch = ip.preprocess_batch(input_sentences, src_lang=src_lang, tgt_lang=tgt_lang)\n",
        "\n",
        "# Tokenize the sentences and generate input encodings\n",
        "inputs = tokenizer(\n",
        "    batch,\n",
        "    truncation=True,\n",
        "    padding=\"longest\",\n",
        "    return_tensors=\"pt\",\n",
        ").to(DEVICE)  # Move inputs to the same device as the model\n",
        "\n",
        "# Generate translations using the model\n",
        "with torch.no_grad():\n",
        "    generated_tokens = base_model.generate(\n",
        "        **inputs,\n",
        "        use_cache=True,\n",
        "        min_length=0,\n",
        "        max_length=256,\n",
        "        num_beams=5,\n",
        "        num_return_sequences=1,\n",
        "    )\n",
        "\n",
        "# Decode the generated tokens into text\n",
        "with tokenizer.as_target_tokenizer():\n",
        "    generated_tokens = tokenizer.batch_decode(\n",
        "        generated_tokens.detach().cpu().tolist(),\n",
        "        skip_special_tokens=True,\n",
        "        clean_up_tokenization_spaces=True,\n",
        "    )\n",
        "\n",
        "# Postprocess the translations\n",
        "translations = ip.postprocess_batch(generated_tokens, lang=tgt_lang)\n",
        "\n",
        "# Print the results\n",
        "for input_sentence, translation in zip(input_sentences, translations):\n",
        "    print(f\"Source: {input_sentence}\")\n",
        "    print(f\"Translation: {translation}\\n\")\n"
      ],
      "metadata": {
        "id": "5wrdXl0DA9Vs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1ae48b5-ac7c-48fd-ebba-0abedbf14fd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source: \"Oxidants and Reductants Compounds that are capable of accepting electrons, such as O 2 or F2, are calledoxidants (or oxidizing agents) because they can oxidize other compounds. In the process of accepting electrons, an oxidant is reduced. Compounds that are capable of donating electrons, such as sodium metal or cyclohexane (C6H12), are calledreductants (or reducing agents) because they can cause the reduction of another compound. In the process of donating electrons, a reductant is oxidized. These relationships are summarized in Equation 3.30: Equation 3.30 Saylor URL: http://www. saylor. org/books.\"\n",
            "Translation: \"O2 లేదా F2 వంటి ఎలక్ట్రాన్లను ఆమోదించగల సామర్థ్యం ఉన్న ఆక్సిడెంట్లు మరియు రిడక్టంట్లు సమ్మేళనాలను ఆక్సిడెంట్లు (లేదా ఆక్సిడైజింగ్ ఏజెంట్లు) అని పిలుస్తారు, ఎందుకంటే అవి ఇతర సమ్మేళనాలను ఆక్సీకరించగలవు. ఎలక్ట్రాన్లను అంగీకరించే ప్రక్రియలో, ఒక ఆక్సిడెంట్ తగ్గించబడుతుంది. సోడియం మెటల్ లేదా సైక్లోహెక్సేన్ (C6H12) వంటి ఎలక్ట్రాన్లను దానం చేయగల సామర్ధ్యాన్ని కలిగి ఉన్న సమ్మేళనాలను రిడక్టంట్లు (లేదా తగ్గించే ఏజెంట్లు) అని పిలుస్తారు, ఎందుకంటే అవి మరొక సమ్మేళనం తగ్గడానికి కారణమవుతాయి. ఎలక్ట్రాన్లను దానం చేసే ప్రక్రియలో, ఒక రిడక్టంట్ ఆక్సీకరణ చెందుతుంది. ఈ సంబంధాలను సమీకరణం 3:30 లో సంగ్రహిస్తారుః సమీకరణం 3:30 సెలర్ URL: \n",
            "\n",
            "Source: \"But transgenic animals just have one novel gene. What about an animal with a whole new genome? Could a clone , a genetically exact copy of an organism, be developed using techniques associated with biotechnology? It could be argued that human cloning is one of the inevitable outcomes of modern biotechnology. It \"\"simply\"\" involves the removal of the nucleus from a somatic cell and its placement into an unfertilized egg cell whose nucleus has either been deactivated or removed. This new cell would mimic the zygote, the first diploid cell of a new organism. This new zygote is allowed to become established, and a few days later is placed into the uterus of a surrogate mother. Theoretically this would result in an individual genetically identical to the donor. Obviously, there are many ethical and legal issues associated with human cloning, and of course, it is not a \"\"simple\"\" procedure. But animal cloning is arguably a different story.\"\n",
            "Translation: \"కానీ జన్యు మార్పిడి జంతువులకు కేవలం ఒక కొత్త జన్యువు ఉంటుంది. ఒక కొత్త జన్యువు ఉన్న జంతువు గురించి ఏమిటి? బయోటెక్నాలజీకి సంబంధించిన పద్ధతులను ఉపయోగించి ఒక క్లోన్, ఒక జీవి యొక్క జన్యుపరంగా ఖచ్చితమైన కాపీని అభివృద్ధి చేయవచ్చా? మానవ క్లోనింగ్ అనేది ఆధునిక బయోటెక్నాలజీ యొక్క అనివార్య ఫలితాలలో ఒకటి అని వాదించవచ్చు. ఇందులో\" \"సరళంగా\" \"సోమాటిక్ సెల్ నుండి కేంద్రకాన్ని తొలగించడం మరియు దాని కేంద్రకం నిష్క్రియం చేయబడిన లేదా తొలగించబడిన ఫలదీకరణ లేని గుడ్డు కణంలో ఉంచడం ఉంటుంది. ఈ కొత్త కణం కొత్త జీవి యొక్క మొదటి ద్విగుణ కణమైన జైగోట్ను అనుకరిస్తుంది. ఈ కొత్త జైగోట్ స్థిరపడటానికి అనుమతించబడుతుంది, మరియు కొన్ని రోజుల తరువాత సర్రోగేట్ తల్లి గర్భాశయంలోకి ఉంచబడుతుంది. సిద్ధాంతపరంగా ఇది దాతకు జన్యుపరంగా సారూప్యమైన ఒక వ్యక్తికి దారితీస్తుంది. సహజంగానే, అనేక నైతిక సమస్యలు ఉన్నాయి మరియు ఇది జంతువు క్లోనింగ్ ప్రక్రియకు సంబంధించినది కాదు\". \n",
            "\n",
            "Source: \"Figure 29.7 Vertebrata are characterized by the presence of a backbone, such as the one that runs through the middle of this fish. All vertebrates are in the Craniata clade and have a cranium. (credit: Ernest V. More; taken at Smithsonian Museum of Natural History, Washington, D.\"\n",
            "Translation: \"చిత్రం 29.7 వెర్టెబ్రాటా ఈ చేప మధ్యలో నడిచే వెన్నెముక వంటి వెన్నెముక ఉనికిని కలిగి ఉంటుంది. సకశేరుకాలన్నీ క్రానియాటా క్లేడ్లో ఉంటాయి మరియు కపాలం కలిగి ఉంటాయి. (క్రెడిట్ః ఎర్నెస్ట్ వి. మోర్; స్మిత్సోనియన్ మ్యూజియం ఆఫ్ నేచురల్ హిస్టరీ, వాషింగ్టన్, డి. లో తీసుకోబడింది\". \n",
            "\n",
            "Source: \"As you know, the surface of Earth is not flat. Some places are high, and some places are low. For example, mountain ranges like the Sierra Nevada in California or the Andes in South America are high above the surrounding areas. An accurate location must take into account the third dimension. Elevation is the height above or below sea level. Sea level refers to the height of the ocean’s surface. This is the midpoint between high and low tide. Sea level can vary from place to place, but scientists base their elevation measurements on the average, or mean, sea level to make sure they have a standard reference point.\"\n",
            "Translation: \"మీకు తెలిసినట్లుగా, భూమి యొక్క ఉపరితలం చదునుగా ఉండదు. కొన్ని ప్రదేశాలు ఎత్తైనవి, కొన్ని ప్రదేశాలు తక్కువగా ఉంటాయి. ఉదాహరణకు, కాలిఫోర్నియాలోని సియెర్రా నెవాడా లేదా దక్షిణ అమెరికాలోని అండీస్ వంటి పర్వత శ్రేణులు చుట్టుపక్కల ప్రాంతాల కంటే ఎక్కువగా ఉంటాయి. ఖచ్చితమైన స్థానం మూడవ కోణాన్ని పరిగణనలోకి తీసుకోవాలి. ఎత్తు అనేది సముద్ర మట్టానికి పైన లేదా క్రింద ఉన్న ఎత్తు. సముద్ర మట్టం అనేది సముద్ర ఉపరితలం యొక్క ఎత్తును సూచిస్తుంది. ఇది అధిక మరియు తక్కువ ఆటుపోట్ల మధ్య మధ్య బిందువు. సముద్ర మట్టం ప్రదేశానికి ప్రదేశానికి మారవచ్చు, కానీ శాస్త్రవేత్తలు వాటి ఎత్తు కొలతలను సగటు లేదా సగటు సముద్ర మట్టంపై ఆధారపరుస్తారు, అవి ప్రామాణిక సూచన బిందువును కలిగి ఉన్నాయని నిర్ధారించుకోండి\". \n",
            "\n",
            "Source: \"Tree rings, ice cores, and varves indicate the environmental conditions at the time they were made.\"\n",
            "Translation: \"చెట్ల వలయాలు, మంచు కోర్లు మరియు కడ్డీలు అవి తయారు చేయబడిన సమయంలో పర్యావరణ పరిస్థితులను సూచిస్తాయి\". \n",
            "\n",
            "Source: Plant hormones are chemical signals that control different processes in plants.\n",
            "Translation: మొక్కల హార్మోన్లు అనేవి మొక్కలలో వివిధ ప్రక్రియలను నియంత్రించే రసాయన సంకేతాలు. \n",
            "\n",
            "Source: \"Gametogenesis (Spermatogenesis and Oogenesis) Gametogenesis, the production of sperm and eggs, involves the process of meiosis. During meiosis, two nuclear divisions separate the paired chromosomes in the nucleus and then separate the chromatids that were made during an earlier stage of the cell’s life cycle. Meiosis and its associated cell divisions produces haploid cells with half of each pair of chromosomes normally found in diploid cells. The production of sperm is called spermatogenesis and the production of eggs is called oogenesis. Spermatogenesis Spermatogenesis occurs in the wall of the seminiferous tubules, with the most primitive cells at the periphery of the tube and the most mature sperm at the lumen of the tube (Figure 18.14). Immediately under the capsule of the tubule are diploid, undifferentiated cells. These stem cells, each called a spermatogonium (pl. spermatogonia), go through mitosis to produce one cell that remains as a stem cell and a second cell called a primary spermatocyte that will undergo meiosis to produce sperm. The diploid primary spermatocyte goes through meiosis I to produce two haploid cells called secondary spermatocytes. Each secondary spermatocyte divides after meiosis II to produce two cells called spermatids. The spermatids eventually reach the lumen of the tubule and grow a flagellum, becoming sperm cells. Four sperm result from each primary spermatocyte that goes through meiosis.\"\n",
            "Translation: \"గామెటోజెనిసిస్ (స్పెర్మోటోజెనిసిస్ మరియు ఊజెనిసిస్) గామెటోజెనిసిస్, వీర్యం మరియు గుడ్ల ఉత్పత్తి, మియోసిస్ ప్రక్రియను కలిగి ఉంటుంది. మియోసిస్ సమయంలో, రెండు అణు విభాగాలు న్యూక్లియస్లోని జత చేసిన క్రోమోజోమ్లను వేరు చేసి, ఆపై కణం యొక్క జీవిత చక్రం యొక్క ప్రారంభ దశలో తయారైన క్రోమాటిడ్లను వేరు చేస్తాయి. మియోసిస్ మరియు దాని అనుబంధ కణ విభాగాలు సాధారణంగా ద్విగుణ కణాలలో కనిపించే ప్రతి జత క్రోమోజోమ్లలో సగానికి హాప్లోయిడ్ కణాలను ఉత్పత్తి చేస్తాయి. వీర్య ఉత్పత్తిని స్పెర్మటోజెనిసిస్ అని పిలుస్తారు మరియు గుడ్ల ఉత్పత్తిని ఊజెనిసిస్ అని పిలుస్తారు. వీర్యజనన స్పెర్మటోజెనిసిస్ సెమినిఫెరస్ గొట్టాల గోడలో జరుగుతుంది, గొట్టం యొక్క చుట్టుపక్కల అత్యంత ఆదిమ కణాలు మరియు లుమెన్ ట్యూబ్ యొక్క లుమెన్ వద్ద అత్యంత పరిణతి చెందిన వీర్యాన్ని కలిగి ఉంటుంది (చిత్రం 18.14). ఈ కణ కణాల యొక్క స్టెమ్ప్లోజెనిసిస్ అని పిలువబడే ఒక ప్రాధమిక కణ కణాలు, అవి వెంటనే ఒక కణ కణ స్టెమ్ప్లోజెనిసిస్ ద్వారా మిగిలిపోతాయి, ఇవి ఒక కణ స్టెమ్ప్లోజెరోసిస్ అని పిలువబడే \n",
            "\n",
            "Source: Figure 44.18 Deciduous trees are the dominant plant in the temperate forest. (credit: Oliver Herold).\n",
            "Translation: చిత్రం 44.18 ఆకురాల్చే చెట్లు సమశీతోష్ణ అడవిలో ప్రబలమైన మొక్క. (క్రెడిట్ః ఆలివర్ హెరాల్డ్). \n",
            "\n",
            "Source: \"There is also a correlation between viscosity and molecular shape. Liquids consisting of long, flexible molecules tend to have higher viscosities than those composed of more spherical or shorter-chain molecules. The longer the molecules, the easier it is for them to become “tangled” with one another, making it more difficult for them to move past one another. London dispersion forces also increase with chain length. Due to a combination of these two effects, long-chain hydrocarbons (such as motor oils) are highly viscous.\"\n",
            "Translation: \"స్నిగ్ధత మరియు పరమాణు ఆకారం మధ్య కూడా సంబంధం ఉంది. పొడవైన, సౌకర్యవంతమైన అణువులతో కూడిన ద్రవాలు ఎక్కువ గోళాకార లేదా చిన్న-గొలుసు అణువులతో కూడిన వాటి కంటే ఎక్కువ స్నిగ్ధతను కలిగి ఉంటాయి. అణువులు ఎంత పొడవుగా ఉంటే, అవి ఒకదానితో ఒకటి\" \"చిక్కుకుపోతాయి\", \"తద్వారా అవి ఒకదానికొకటి దాటడం మరింత కష్టమవుతుంది. లండన్ వ్యాప్తి శక్తులు కూడా గొలుసు పొడవుతో పెరుగుతాయి. ఈ రెండు ప్రభావాల కలయిక కారణంగా, పొడవైన గొలుసు హైడ్రోకార్బన్లు (మోటారు నూనెలు వంటివి) చాలా జిగటగా ఉంటాయి\". \n",
            "\n",
            "Source: \"Ionic compounds have strong electrostatic attractions between oppositely charged ions in a regular array. The lattice energy (U) of an ionic substance is defined as the energy required to dissociate the solid into gaseous ions; U can be calculated from the charges on the ions, the arrangement of the ions in the solid, and the internuclear distance. Because U depends on the product of the ionic charges, substances with dior tripositive cations and/or di- or trinegative anions tend to have higher lattice energies than their singly charged counterparts. Higher lattice energies typically result in higher melting points and increased hardnessbecause more thermal energy is needed to overcome the forces that hold the ions together. Lattice energies cannot be measured directly but are obtained from a thermochemical cycle called the Born–Haber cycle, in which Hess’s law is used to calculate the lattice energy from the measured enthalpy of formation of the ionic compound, along with other thermochemical data. The Born–Haber cycle can be used to predict which ionic compounds are likely to form. Sublimation, the conversion of a solid directly to a gas, has an accompanying enthalpy change called the enthalpy of sublimation.\"\n",
            "Translation: అయానిక్ సమ్మేళనాలు ఒక సాధారణ శ్రేణిలో వ్యతిరేక చార్జ్ చేయబడిన అయాన్ల మధ్య బలమైన స్థిర విద్యుత్ ఆకర్షణలను కలిగి ఉంటాయి. అయానిక్ పదార్ధం యొక్క జాలక శక్తి (U) అనేది ఘనపదార్థాన్ని వాయు అయాన్లుగా విడదీయడానికి అవసరమైన శక్తిగా నిర్వచించబడుతుంది; అయాన్లపై ఛార్జీల నుండి, ఘనపదార్థంలోని అయాన్ల అమరిక మరియు ఇంటర్నేషనల్ దూరం నుండి Uని లెక్కించవచ్చు. ఎందుకంటే U అయానిక్ ఛార్జీల ఉత్పత్తి మీద ఆధారపడి ఉంటుంది, డియోర్ ట్రైపోజిటివ్ కాటయాన్స్ మరియు/లేదా డై-లేదా ట్రైనెగేటివ్ అయాన్లు ఉన్న పదార్థాలు వాటి సింగిల్ ఛార్జ్ చేసిన ప్రత్యర్ధుల కంటే ఎక్కువ జాలక శక్తులను కలిగి ఉంటాయి. అధిక జాలక శక్తులు సాధారణంగా అధిక ద్రవీభవన బిందువులకు మరియు పెరిగిన కాఠిన్యానికి దారితీస్తాయి, ఎందుకంటే అయాన్లను కలిసి ఉంచే శక్తులను అధిగమించడానికి ఎక్కువ ఉష్ణ శక్తి అవసరమవుతుంది. జాలక శక్తులను నేరుగా కొలవలేము, కానీ ఒక థర్మోకెమికల్ చక్రం నుండి పొందవచ్చు, దీనిని బోర్న్-హెస్సెబ్ చక్రం నుండి కొలుస్తారు. \n",
            "\n",
            "Source: \"Besides seamounts, there are long, very tall (about 2 km) mountain ranges. These ranges are connected so that they form huge ridge systems called mid-ocean ridges ( Figure below ). The mid-ocean ridges form from volcanic eruptions. Lava from inside Earth breaks through the crust and creates the mountains.\"\n",
            "Translation: సీమౌంట్లతో పాటు, పొడవైన, చాలా పొడవైన (సుమారు 2 కి. మీ) పర్వత శ్రేణులు ఉన్నాయి. ఈ శ్రేణులు అనుసంధానించబడి ఉంటాయి, తద్వారా అవి మధ్య-సముద్రపు గట్లు అని పిలువబడే భారీ శిఖరాల వ్యవస్థలను ఏర్పరుస్తాయి (క్రింద ఉన్న చిత్రం). మధ్య-సముద్రపు గట్లు అగ్నిపర్వత విస్ఫోటనాల నుండి ఏర్పడతాయి. భూమి లోపలి నుండి లావా క్రస్ట్ గుండా విరిగి పర్వతాలను సృష్టిస్తుంది. \n",
            "\n",
            "Source: \"This Monarch caterpillar is an invertebrate. It is also an insect and an arthropod. Of all the animal species, it is estimated that well over 90% are invertebrates. Of all invertebrates, the insects are by far the most numerous. There are so many species of insects that scientists have yet to discover them all, let alone name or count them. Estimates of the total number of insect species fall in the range of 1 to 30 million. So, it helps if there are methods to classify not just the insects, but all invertebrates.\"\n",
            "Translation: \"ఈ మోనార్క్ గొంగళి పురుగు ఒక అకశేరుకం. ఇది ఒక పురుగు మరియు కీళ్ళరసం కూడా. అన్ని జంతు జాతులలో, 90 శాతానికి పైగా అకశేరుకాలు అని అంచనా వేయబడింది. అన్ని అకశేరుకాలలో, కీటకాలు ఇప్పటివరకు చాలా ఉన్నాయి. శాస్త్రవేత్తలు ఇంకా వాటిని కనుగొనలేకపోయిన అనేక జాతుల కీటకాలు ఉన్నాయి, వాటికి పేరు పెట్టడం లేదా లెక్కించడం ఒక్కటే. మొత్తం కీటక జాతుల సంఖ్య 1 నుండి 30 మిలియన్ల పరిధిలో ఉంటుంది. కాబట్టి, కీటకాలను మాత్రమే కాకుండా, అన్ని అకశేరుకాలను వర్గీకరించే పద్ధతులు ఉంటే ఇది సహాయపడుతుంది\". \n",
            "\n",
            "Source: Waves may also deposit sediments to form sandbars and barrier islands . You can see examples of these landforms in Figure below .\n",
            "Translation: అలలు అవక్షేపాలను నిక్షిప్తం చేసి ఇసుక బార్లు మరియు అవరోధ ద్వీపాలను ఏర్పరుస్తాయి. ఈ భూ ఆకృతుల ఉదాహరణలను మీరు దిగువ చిత్రంలో చూడవచ్చు. \n",
            "\n",
            "Source: \"Male reproductive organs include the penis, testes, and epididymis.\"\n",
            "Translation: పురుష పునరుత్పత్తి అవయవాలలో పురుషాంగం, వృషణాలు మరియు ఎపిడిడైమిస్ ఉన్నాయి. \n",
            "\n",
            "Source: \"Almost all plants make food by photosynthesis . Only about 1 percent of the estimated 300,000 species of plants have lost the ability to photosynthesize. These other species are consumers, many of them predators. How do plants prey on other organisms? The Venus fly trap in Figure below shows one way this occurs.\"\n",
            "Translation: దాదాపు అన్ని మొక్కలు కిరణజన్య సంయోగక్రియ ద్వారా ఆహారాన్ని తయారు చేస్తాయి. అంచనా వేసిన 300,000 జాతుల మొక్కలలో కేవలం 1 శాతం మాత్రమే కిరణజన్య సంయోగక్రియ సామర్థ్యాన్ని కోల్పోయాయి. ఈ ఇతర జాతులు వినియోగదారులు, వాటిలో చాలా వరకు మాంసాహారులు. మొక్కలు ఇతర జీవులను ఎలా వేటాడతాయి? దిగువ చిత్రంలో వీనస్ ఫ్లై ట్రాప్ ఇది ఎలా జరుగుతుందో చూపిస్తుంది. \n",
            "\n",
            "Source: \"A neon light produces visible light by electroluminescence. The bulb is a glass tube that contains the noble gas neon. When electricity passes through the gas, it excites electrons of neon atoms, causing them to give off visible light. Neon produces red light. Other noble gases are also used in lights, and they produce light of different colors. For example, krypton produces violet light, and argon produces blue light.\"\n",
            "Translation: \"నియాన్ కాంతి ఎలెక్ట్రోలుమినిసెన్స్ ద్వారా కనిపించే కాంతిని ఉత్పత్తి చేస్తుంది. బల్బ్ అనేది గొప్ప వాయువు నియాన్ను కలిగి ఉన్న గాజు గొట్టం. విద్యుత్ వాయువు గుండా వెళ్ళినప్పుడు, అది నియాన్ అణువుల ఎలక్ట్రాన్లను ఉత్తేజపరుస్తుంది, తద్వారా అవి కనిపించే కాంతిని విడుదల చేస్తాయి. నియాన్ ఎరుపు కాంతిని ఉత్పత్తి చేస్తుంది. ఇతర గొప్ప వాయువులను కూడా దీపాలలో ఉపయోగిస్తారు, అవి వివిధ రంగుల కాంతిని ఉత్పత్తి చేస్తాయి. ఉదాహరణకు, క్రిప్టాన్ వైలెట్ కాంతిని ఉత్పత్తి చేస్తుంది, ఆర్గాన్ నీలం కాంతిని ఉత్పత్తి చేస్తుంది\". \n",
            "\n",
            "Source: \"Wings evolved in a bird ancestor that lived in trees. Thus, wings are modified arms that helped the animal glide from branch to branch.\"\n",
            "Translation: \"చెట్లలో నివసించే పక్షి పూర్వీకులలో రెక్కలు ఉద్భవించాయి. అందువల్ల, రెక్కలు అనేవి జంతువు కొమ్మ నుండి కొమ్మకు ఎగరడానికి సహాయపడే సవరించిన చేతులు\". \n",
            "\n",
            "Source: \"Today, most living things use oxygen to make ATP from glucose. However, many living things can also make ATP without oxygen. This is true of some plants and fungi and also of many bacteria. These organisms use aerobic respiration when oxygen is present, but when oxygen is in short supply, they use anaerobic respiration instead. Certain bacteria can only use anaerobic respiration. In fact, they may not be able to survive at all in the presence of oxygen.\"\n",
            "Translation: \"నేడు, చాలా జీవులు గ్లూకోజ్ నుండి ATPని తయారు చేయడానికి ఆక్సిజన్ను ఉపయోగిస్తాయి. అయితే, చాలా జీవులు ఆక్సిజన్ లేకుండా ATPని కూడా తయారు చేయగలవు. ఇది కొన్ని మొక్కలు మరియు శిలీంధ్రాలు మరియు అనేక బ్యాక్టీరియా విషయంలో కూడా వర్తిస్తుంది. ఈ జీవులు ఆక్సిజన్ ఉన్నప్పుడు ఏరోబిక్ శ్వాసక్రియను ఉపయోగిస్తాయి, కానీ ఆక్సిజన్ కొరత ఉన్నప్పుడు, అవి వాయురహిత శ్వాసక్రియను ఉపయోగిస్తాయి. కొన్ని బ్యాక్టీరియా వాయురహిత శ్వాసక్రియను మాత్రమే ఉపయోగించగలవు. వాస్తవానికి, అవి ఆక్సిజన్ సమక్షంలో అస్సలు మనుగడ సాగించలేకపోవచ్చు\". \n",
            "\n",
            "Source: \"Feldspar and quartz are the two most common silicates. In beryl, the silicate pyramids join together as rings. Biotite is mica. It can be broken apart into thin, flexible sheets. Compare the beryl and the biotite shown in Figure below .\"\n",
            "Translation: \"ఫెల్డ్స్పార్ మరియు క్వార్ట్జ్ అనేవి రెండు అత్యంత సాధారణ సిలికేట్లు. బెరీల్లో, సిలికేట్ పిరమిడ్లు వలయాలుగా కలిసిపోతాయి. బయోటైట్ మైకా. దీనిని సన్నని, అనువైన పలకలుగా విభజించవచ్చు. దిగువ చిత్రంలో చూపిన బెరిల్ మరియు బయోటైట్లను పోల్చండి\". \n",
            "\n",
            "Source: Humidity is the amount of water vapor in the air. High humidity increases the chances of clouds and precipitation.\n",
            "Translation: తేమ అంటే గాలిలో నీటి ఆవిరి పరిమాణం. అధిక తేమ మేఘాలు మరియు అవపాతం వచ్చే అవకాశాలను పెంచుతుంది. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to the zip file\n",
        "zip_file_path = '/content/fine_tuned_model_telugu_Scientific_dataset.zip'\n",
        "\n",
        "# Path to extract the files\n",
        "extract_to_path = '/content/fine_tuned_model_telugu'\n",
        "\n",
        "# Create the extraction directory if it doesn't exist\n",
        "os.makedirs(extract_to_path, exist_ok=True)\n",
        "\n",
        "# Unzipping the folder\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to_path)\n",
        "\n",
        "print(f\"Files have been unzipped to: {extract_to_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJwjUlGtUc_S",
        "outputId": "8c37e5d1-fa4d-44f1-dc49-de38b0c1143c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files have been unzipped to: /content/fine_tuned_model_telugu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from peft import PeftModel\n",
        "from IndicTransToolkit import IndicProcessor\n",
        "\n",
        "# Load the base model\n",
        "base_ckpt_dir = \"ai4bharat/indictrans2-en-indic-dist-200M\"  # Change this as per your use case\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_ckpt_dir, trust_remote_code=True)\n",
        "base_model = AutoModelForSeq2SeqLM.from_pretrained(base_ckpt_dir, trust_remote_code=True)\n",
        "\n",
        "# Load the LoRA model\n",
        "lora_ckpt_dir = \"/content/fine_tuned_model_telugu\"  # Path to your fine-tuned model directory\n",
        "lora_model = PeftModel.from_pretrained(base_model, lora_ckpt_dir)\n",
        "\n",
        "# Move the model to the appropriate device\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "lora_model.to(DEVICE)\n",
        "\n",
        "# Test translation with your model\n",
        "input_sentences = scientific_sentences\n",
        "\n",
        "# Preprocess and translate\n",
        "src_lang, tgt_lang = \"eng_Latn\", \"tel_Telu\"  # Adjust target language as needed\n",
        "ip = IndicProcessor(inference=True)\n",
        "\n",
        "# Preprocess input sentences\n",
        "batch = ip.preprocess_batch(input_sentences, src_lang=src_lang, tgt_lang=tgt_lang)\n",
        "\n",
        "# Tokenize the sentences and generate input encodings\n",
        "inputs = tokenizer(\n",
        "    batch,\n",
        "    truncation=True,\n",
        "    padding=\"longest\",\n",
        "    return_tensors=\"pt\",\n",
        ").to(DEVICE)  # Move inputs to the same device as the model\n",
        "\n",
        "# Generate translations using the model\n",
        "with torch.no_grad():\n",
        "    generated_tokens = lora_model.generate(\n",
        "        **inputs,\n",
        "        use_cache=True,\n",
        "        min_length=0,\n",
        "        max_length=256,\n",
        "        num_beams=5,\n",
        "        num_return_sequences=1,\n",
        "    )\n",
        "\n",
        "# Decode the generated tokens into text\n",
        "with tokenizer.as_target_tokenizer():\n",
        "    generated_tokens = tokenizer.batch_decode(\n",
        "        generated_tokens.detach().cpu().tolist(),\n",
        "        skip_special_tokens=True,\n",
        "        clean_up_tokenization_spaces=True,\n",
        "    )\n",
        "\n",
        "# Postprocess the translations\n",
        "translations = ip.postprocess_batch(generated_tokens, lang=tgt_lang)\n",
        "\n",
        "# Print the results\n",
        "for input_sentence, translation in zip(input_sentences, translations):\n",
        "    print(f\"Source: {input_sentence}\")\n",
        "    print(f\"Translation: {translation}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nswd3mP2UHjk",
        "outputId": "3e9933ea-0004-413a-9c3f-64121003b526"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source: \"Oxidants and Reductants Compounds that are capable of accepting electrons, such as O 2 or F2, are calledoxidants (or oxidizing agents) because they can oxidize other compounds. In the process of accepting electrons, an oxidant is reduced. Compounds that are capable of donating electrons, such as sodium metal or cyclohexane (C6H12), are calledreductants (or reducing agents) because they can cause the reduction of another compound. In the process of donating electrons, a reductant is oxidized. These relationships are summarized in Equation 3.30: Equation 3.30 Saylor URL: http://www. saylor. org/books.\"\n",
            "Translation: O2 లేదా F2 వంటి ఎలక్ట్రాన్లను స్వీకరించగల సామర్థ్యం ఉన్న ఆక్సిడెంట్లు మరియు రిడక్టంట్ల సమ్మేళనాలను ఆక్సిడెంట్లు (లేదా ఆక్సిడైజింగ్ ఏజెంట్లు) అంటారు, ఎందుకంటే అవి ఇతర సమ్మేళనాలను ఆక్సిడైజ్ చేయగలవు. ఎలక్ట్రాన్లను స్వీకరించే ప్రక్రియలో, ఒక ఆక్సిడెంట్ తగ్గిపోతుంది. సోడియం మెటల్ లేదా సైక్లోహెక్సేన్ (C6H12) వంటి ఎలక్ట్రాన్లను దానం చేయగల సామర్థ్యం ఉన్న సమ్మేళనాలను రిడక్టంట్లు (లేదా తగ్గించే ఏజెంట్లు) అంటారు, ఎందుకంటే అవి మరొక సమ్మేళనం యొక్క తగ్గింపుకు కారణమవుతాయి. ఎలక్ట్రాన్లను దానం చేసే ప్రక్రియలో, ఒక రిడక్టంట్ ఆక్సిడైజ్ చేయబడుతుంది. ఈ సంబంధాలను సమీకరణం 3:30: సమీకరణం 3:30 లో సంగ్రహించారు. \n",
            "\n",
            "Source: \"But transgenic animals just have one novel gene. What about an animal with a whole new genome? Could a clone , a genetically exact copy of an organism, be developed using techniques associated with biotechnology? It could be argued that human cloning is one of the inevitable outcomes of modern biotechnology. It \"\"simply\"\" involves the removal of the nucleus from a somatic cell and its placement into an unfertilized egg cell whose nucleus has either been deactivated or removed. This new cell would mimic the zygote, the first diploid cell of a new organism. This new zygote is allowed to become established, and a few days later is placed into the uterus of a surrogate mother. Theoretically this would result in an individual genetically identical to the donor. Obviously, there are many ethical and legal issues associated with human cloning, and of course, it is not a \"\"simple\"\" procedure. But animal cloning is arguably a different story.\"\n",
            "Translation: కానీ జన్యుమార్పిడి జంతువులకు ఒక కొత్త జన్యువు ఉంటుంది. కొత్త జన్యువు కలిగిన జంతువు గురించి ఏమిటి? జీవ సాంకేతిక పరిజ్ఞానానికి సంబంధించిన పద్ధతులను ఉపయోగించి ఒక క్లోన్, ఒక జీవి యొక్క జన్యుపరంగా ఖచ్చితమైన కాపీని అభివృద్ధి చేయవచ్చా? మానవ క్లోనింగ్ అనేది ఆధునిక జీవ సాంకేతిక పరిజ్ఞానం యొక్క అనివార్య ఫలితాలలో ఒకటి అని వాదించవచ్చు. ఇందులో \"సరళంగా\" సోమాటిక్ కణం నుండి కేంద్రకాన్ని తొలగించడం మరియు దాని కేంద్రకాన్ని నిష్క్రియం చేసిన లేదా తొలగించిన ఫలదీకరణ లేని గుడ్డు కణంగా ఉంచడం ఉంటుంది. ఈ కొత్త కణం కొత్త జీవి యొక్క మొదటి ద్విగుణ కణమైన జైగోట్ను అనుకరిస్తుంది. ఈ కొత్త జైగోట్ స్థిరపడటానికి అనుమతించబడుతుంది, మరియు కొన్ని రోజుల తరువాత సర్రోగేట్ తల్లి గర్భాశయంలోకి ఉంచబడుతుంది. సిద్ధాంతపరంగా ఇది దాతకు జన్యుపరంగా సమానమైన వ్యక్తికి దారితీస్తుంది. సహజంగానే, మరియు మానవ క్లోనింగ్ తో సంబంధం ఉన్న అనేక నైతిక సమస్యలు ఉన్నాయి, కానీ ఇది ఒక సాధారణ ప్రక్రియ కాదు. \n",
            "\n",
            "Source: \"Figure 29.7 Vertebrata are characterized by the presence of a backbone, such as the one that runs through the middle of this fish. All vertebrates are in the Craniata clade and have a cranium. (credit: Ernest V. More; taken at Smithsonian Museum of Natural History, Washington, D.\"\n",
            "Translation: చిత్రం 29.7 వెర్టెబ్రాటా ఒక వెన్నెముక ఉనికిని కలిగి ఉంటుంది, ఉదాహరణకు ఈ చేప మధ్యలో ప్రవహించే వెన్నెముక. అన్ని వెన్నుముకలు క్రానియాటా క్లేడ్లో ఉంటాయి మరియు కపాలం కలిగి ఉంటాయి. (క్రెడిట్ః ఎర్నెస్ట్ V. మోర్; స్మిత్సోనియన్ మ్యూజియం ఆఫ్ నేచురల్ హిస్టరీ, వాషింగ్టన్, D. \n",
            "\n",
            "Source: \"As you know, the surface of Earth is not flat. Some places are high, and some places are low. For example, mountain ranges like the Sierra Nevada in California or the Andes in South America are high above the surrounding areas. An accurate location must take into account the third dimension. Elevation is the height above or below sea level. Sea level refers to the height of the ocean’s surface. This is the midpoint between high and low tide. Sea level can vary from place to place, but scientists base their elevation measurements on the average, or mean, sea level to make sure they have a standard reference point.\"\n",
            "Translation: మీకు తెలిసినట్లుగా, భూమి యొక్క ఉపరితలం చదునుగా ఉండదు. కొన్ని ప్రదేశాలు ఎత్తైనవి మరియు కొన్ని ప్రదేశాలు తక్కువగా ఉంటాయి. ఉదాహరణకు, కాలిఫోర్నియాలోని సియెర్రా నెవాడా లేదా దక్షిణ అమెరికాలోని ఆండిస్ వంటి పర్వత శ్రేణులు చుట్టుపక్కల ప్రాంతాల కంటే ఎత్తైనవి. ఖచ్చితమైన స్థానం మూడవ పరిమాణాన్ని పరిగణనలోకి తీసుకోవాలి. ఎత్తు అంటే సముద్ర మట్టానికి పైన లేదా క్రింద ఉన్న ఎత్తు. సముద్ర మట్టం సముద్రపు ఉపరితలం యొక్క ఎత్తును సూచిస్తుంది. ఇది అధిక మరియు తక్కువ ఆటుపోట్ల మధ్య మధ్య బిందువు. సముద్ర మట్టం ప్రదేశానికి ప్రదేశానికి మారవచ్చు, కానీ శాస్త్రవేత్తలు వాటి ఎత్తును సగటు లేదా సగటు సముద్ర మట్టంపై కొలుస్తారు, తద్వారా వాటికి ప్రామాణిక సూచన బిందువు ఉండేలా చూసుకోవచ్చు. \n",
            "\n",
            "Source: \"Tree rings, ice cores, and varves indicate the environmental conditions at the time they were made.\"\n",
            "Translation: చెట్ల వలయాలు, మంచు కోర్లు మరియు కడ్డీలు అవి తయారైన సమయంలో పర్యావరణ పరిస్థితులను సూచిస్తాయి. \n",
            "\n",
            "Source: Plant hormones are chemical signals that control different processes in plants.\n",
            "Translation: మొక్కలలోని వివిధ ప్రక్రియలను నియంత్రించే రసాయన సంకేతాలు మొక్కలలోని హార్మోన్లు. \n",
            "\n",
            "Source: \"Gametogenesis (Spermatogenesis and Oogenesis) Gametogenesis, the production of sperm and eggs, involves the process of meiosis. During meiosis, two nuclear divisions separate the paired chromosomes in the nucleus and then separate the chromatids that were made during an earlier stage of the cell’s life cycle. Meiosis and its associated cell divisions produces haploid cells with half of each pair of chromosomes normally found in diploid cells. The production of sperm is called spermatogenesis and the production of eggs is called oogenesis. Spermatogenesis Spermatogenesis occurs in the wall of the seminiferous tubules, with the most primitive cells at the periphery of the tube and the most mature sperm at the lumen of the tube (Figure 18.14). Immediately under the capsule of the tubule are diploid, undifferentiated cells. These stem cells, each called a spermatogonium (pl. spermatogonia), go through mitosis to produce one cell that remains as a stem cell and a second cell called a primary spermatocyte that will undergo meiosis to produce sperm. The diploid primary spermatocyte goes through meiosis I to produce two haploid cells called secondary spermatocytes. Each secondary spermatocyte divides after meiosis II to produce two cells called spermatids. The spermatids eventually reach the lumen of the tubule and grow a flagellum, becoming sperm cells. Four sperm result from each primary spermatocyte that goes through meiosis.\"\n",
            "Translation: వీర్యం మరియు గుడ్ల ఉత్పత్తి అయిన గామెటోజెనిసిస్, వీర్యం మరియు గుడ్ల ఉత్పత్తిని కలిగి ఉంటుంది. మియోసిస్ సమయంలో, రెండు న్యూక్లియర్ విభాగాలు కేంద్రకంలోని జత క్రోమోజోమ్లను వేరు చేసి, ఆపై కణం యొక్క జీవిత చక్రం ప్రారంభ దశలో తయారైన క్రోమాటిడ్లను వేరు చేస్తాయి. మియోసిస్ మరియు దాని అనుబంధ కణ విభాగాలు సాధారణంగా ద్విగుణ కణాలలో కనిపించే ప్రతి జత క్రోమోజోమ్లలో సగానికి హాప్లోయిడ్ కణాలను ఉత్పత్తి చేస్తాయి. వీర్య ఉత్పత్తిని స్పెర్మటోజెనిసిస్ అని పిలుస్తారు మరియు గుడ్ల ఉత్పత్తిని ఊజెనిసిస్ అంటారు. స్పెర్మటోజెనిసిస్ స్పెర్మటోజెనిసిస్ సెమినిఫెరస్ గొట్టాల గోడలో జరుగుతుంది, గొట్టం యొక్క చుట్టుపక్కల అత్యంత ప్రాచీన కణాలు మరియు గొట్టం యొక్క లుమెన్ వద్ద అత్యంత పరిణతి చెందిన వీర్యంతో. \n",
            "\n",
            "Source: Figure 44.18 Deciduous trees are the dominant plant in the temperate forest. (credit: Oliver Herold).\n",
            "Translation: ఆకురాల్చే చెట్లు సమశీతోష్ణ అడవిలో ప్రధానమైన మొక్కలు. (క్రెడిట్ః ఒలివర్ హెరాల్డ్) \n",
            "\n",
            "Source: \"There is also a correlation between viscosity and molecular shape. Liquids consisting of long, flexible molecules tend to have higher viscosities than those composed of more spherical or shorter-chain molecules. The longer the molecules, the easier it is for them to become “tangled” with one another, making it more difficult for them to move past one another. London dispersion forces also increase with chain length. Due to a combination of these two effects, long-chain hydrocarbons (such as motor oils) are highly viscous.\"\n",
            "Translation: స్నిగ్ధత మరియు పరమాణు ఆకారం మధ్య కూడా సంబంధం ఉంది. పొడవైన, సౌకర్యవంతమైన అణువులతో కూడిన ద్రవాలు ఎక్కువ గోళాకార లేదా చిన్న-గొలుసు అణువులతో తయారైన వాటి కంటే ఎక్కువ స్నిగ్ధతను కలిగి ఉంటాయి. అణువులు ఎంత పొడవుగా ఉంటే, అవి ఒకదానితో ఒకటి \"చిక్కుకుపోవడం\" సులభం అవుతుంది, తద్వారా అవి ఒకదానికొకటి దాటడం మరింత కష్టం అవుతుంది. లండన్ వ్యాప్తి శక్తులు కూడా గొలుసు పొడవుతో పెరుగుతాయి. ఈ రెండు ప్రభావాల కలయిక కారణంగా, పొడవైన గొలుసు హైడ్రోకార్బన్లు (మోటారు నూనెలు వంటివి) చాలా స్నిగ్ధంగా ఉంటాయి. \n",
            "\n",
            "Source: \"Ionic compounds have strong electrostatic attractions between oppositely charged ions in a regular array. The lattice energy (U) of an ionic substance is defined as the energy required to dissociate the solid into gaseous ions; U can be calculated from the charges on the ions, the arrangement of the ions in the solid, and the internuclear distance. Because U depends on the product of the ionic charges, substances with dior tripositive cations and/or di- or trinegative anions tend to have higher lattice energies than their singly charged counterparts. Higher lattice energies typically result in higher melting points and increased hardnessbecause more thermal energy is needed to overcome the forces that hold the ions together. Lattice energies cannot be measured directly but are obtained from a thermochemical cycle called the Born–Haber cycle, in which Hess’s law is used to calculate the lattice energy from the measured enthalpy of formation of the ionic compound, along with other thermochemical data. The Born–Haber cycle can be used to predict which ionic compounds are likely to form. Sublimation, the conversion of a solid directly to a gas, has an accompanying enthalpy change called the enthalpy of sublimation.\"\n",
            "Translation: అయానిక్ సమ్మేళనాలు ఒక సాధారణ శ్రేణిలో వ్యతిరేక చార్జ్ అయాన్ల మధ్య బలమైన విద్యుత్ ఆకర్షణలను కలిగి ఉంటాయి. అయానిక్ పదార్ధం యొక్క జాలక శక్తిని (U) ఘనపదార్థాన్ని వాయు అయాన్లుగా విడదీయడానికి అవసరమైన శక్తిగా నిర్వచిస్తారు; U ని అయాన్లపై ఛార్జీల నుండి లెక్కించవచ్చు, ఘనపదార్థంలోని అయాన్ల అమరిక మరియు ఇంటర్న్యూక్లియర్ దూరం. ఎందుకంటే U అయానిక్ ఛార్జీల యొక్క ఉత్పత్తి మీద ఆధారపడి ఉంటుంది, డియోర్ ట్రైపోజిటివ్ కాటైయన్లు మరియు/లేదా డై-లేదా ట్రైనెగేటివ్ అయాన్లు ఉన్న పదార్థాలు వాటి సింగిల్ ఛార్జ్ చేసిన ప్రత్యర్ధుల కంటే ఎక్కువ జాలక శక్తులను కలిగి ఉంటాయి. అధిక జాలక శక్తులు సాధారణంగా అధిక ద్రవీభవన బిందువులకు దారితీస్తాయి మరియు కాఠిన్యాన్ని పెంచుతాయి-ఎందుకంటే అయాన్లను కలిసి ఉంచే శక్తులను అధిగమించడానికి ఎక్కువ ఉష్ణ శక్తి అవసరం. జాలక శక్తులను నేరుగా కొలవలేము, కానీ ఒక థర్మల్-కెమికల్ చక్రం నుండి పొందవచ్చు, దీనిని బోర్న్-హెస్సబ్ అని పిలుస్తారు, ఇది థర్మల్-కెమికల్ చక్రం నుండి కొలుస్తారు. \n",
            "\n",
            "Source: \"Besides seamounts, there are long, very tall (about 2 km) mountain ranges. These ranges are connected so that they form huge ridge systems called mid-ocean ridges ( Figure below ). The mid-ocean ridges form from volcanic eruptions. Lava from inside Earth breaks through the crust and creates the mountains.\"\n",
            "Translation: సముద్రపు దిబ్బలతో పాటు, పొడవైన, చాలా పొడవైన (సుమారు 2 కిమీ) పర్వత శ్రేణులు ఉన్నాయి. ఈ శ్రేణులు అనుసంధానించబడి ఉన్నాయి, తద్వారా అవి మధ్య సముద్రపు దిబ్బలు అని పిలువబడే భారీ రిడ్జ్ వ్యవస్థలను ఏర్పరుస్తాయి (క్రింద ఉన్న చిత్రం చూడండి). మధ్య సముద్రపు దిబ్బలు అగ్నిపర్వత విస్ఫోటనాల నుండి ఏర్పడతాయి. భూమి లోపలి నుండి లావా క్రస్ట్ గుండా వెళ్లి పర్వతాలను సృష్టిస్తుంది. \n",
            "\n",
            "Source: \"This Monarch caterpillar is an invertebrate. It is also an insect and an arthropod. Of all the animal species, it is estimated that well over 90% are invertebrates. Of all invertebrates, the insects are by far the most numerous. There are so many species of insects that scientists have yet to discover them all, let alone name or count them. Estimates of the total number of insect species fall in the range of 1 to 30 million. So, it helps if there are methods to classify not just the insects, but all invertebrates.\"\n",
            "Translation: ఈ మోనార్క్ గొంగళి పురుగు ఒక అకశేరుక జంతువు. ఇది ఒక పురుగు మరియు కీళ్ళరసం కూడా. అన్ని జంతు జాతులలో, 90 శాతానికి పైగా అకశేరుకాలు అని అంచనా వేయబడింది. అకశేరుకాలలో, కీటకాలు ఇప్పటివరకు చాలా ఉన్నాయి. శాస్త్రవేత్తలు ఇంకా వాటిని కనుగొనలేదు, వాటికి పేరు పెట్టడం లేదా లెక్కించడం ఒక్కటే. మొత్తం కీటక జాతుల సంఖ్య 1 నుండి 30 మిలియన్ల పరిధిలో ఉంటుంది. కాబట్టి, కీటకాలను మాత్రమే కాకుండా, అన్ని అకశేరుకాలను వర్గీకరించే పద్ధతులు ఉంటే ఇది సహాయపడుతుంది. \n",
            "\n",
            "Source: Waves may also deposit sediments to form sandbars and barrier islands . You can see examples of these landforms in Figure below .\n",
            "Translation: అలలు కూడా అవక్షేపాలను జమ చేసి ఇసుక దిబ్బలు మరియు అవరోధ ద్వీపాలను ఏర్పరుస్తాయి. ఈ భూరూపాల ఉదాహరణలను మీరు క్రింది చిత్రంలో చూడవచ్చు. \n",
            "\n",
            "Source: \"Male reproductive organs include the penis, testes, and epididymis.\"\n",
            "Translation: పురుషుల పునరుత్పత్తి అవయవాలలో పురుషాంగం, వృషణాలు మరియు ఎపిడిడైమిస్ ఉన్నాయి. \n",
            "\n",
            "Source: \"Almost all plants make food by photosynthesis . Only about 1 percent of the estimated 300,000 species of plants have lost the ability to photosynthesize. These other species are consumers, many of them predators. How do plants prey on other organisms? The Venus fly trap in Figure below shows one way this occurs.\"\n",
            "Translation: దాదాపు అన్ని మొక్కలు కిరణజన్య సంయోగక్రియ ద్వారా ఆహారాన్ని తయారు చేస్తాయి. అంచనా వేసిన 300,000 జాతుల మొక్కలలో కేవలం 1 శాతం మాత్రమే కిరణజన్య సంయోగక్రియ సామర్థ్యాన్ని కోల్పోయాయి. ఈ ఇతర జాతులు వినియోగదారులు, వాటిలో చాలా వరకు మాంసాహారులు. మొక్కలు ఇతర జీవులను ఎలా వేటాడతాయి? దిగువన ఉన్న చిత్రంలో వీనస్ ఫ్లై ట్రాప్ ఇది ఎలా జరుగుతుందో చూపిస్తుంది. \n",
            "\n",
            "Source: \"A neon light produces visible light by electroluminescence. The bulb is a glass tube that contains the noble gas neon. When electricity passes through the gas, it excites electrons of neon atoms, causing them to give off visible light. Neon produces red light. Other noble gases are also used in lights, and they produce light of different colors. For example, krypton produces violet light, and argon produces blue light.\"\n",
            "Translation: నియాన్ కాంతి ఎలక్ట్రోలుమినిసెన్స్ ద్వారా కనిపించే కాంతిని ఉత్పత్తి చేస్తుంది. బల్బ్ ఒక గాజు గొట్టం, ఇందులో గొప్ప వాయువు నియాన్ ఉంటుంది. వాయువు గుండా విద్యుత్ వెళ్ళినప్పుడు, అది నియాన్ అణువుల ఎలక్ట్రాన్లను ప్రేరేపిస్తుంది, తద్వారా అవి కనిపించే కాంతిని విడుదల చేస్తాయి. నియాన్ ఎర్ర కాంతిని ఉత్పత్తి చేస్తుంది. ఇతర గొప్ప వాయువులను కూడా దీపాలలో ఉపయోగిస్తారు, మరియు అవి వేర్వేరు రంగుల కాంతిని ఉత్పత్తి చేస్తాయి. ఉదాహరణకు, క్రిప్టాన్ వైలెట్ కాంతిని ఉత్పత్తి చేస్తుంది, మరియు ఆర్గాన్ నీలం కాంతిని ఉత్పత్తి చేస్తుంది. \n",
            "\n",
            "Source: \"Wings evolved in a bird ancestor that lived in trees. Thus, wings are modified arms that helped the animal glide from branch to branch.\"\n",
            "Translation: చెట్లలో నివసించే పక్షి పూర్వీకులలో రెక్కలు ఉద్భవించాయి. అందువల్ల, రెక్కలు జంతువు కొమ్మ నుండి కొమ్మకు ఎగరడానికి సహాయపడే సవరించిన చేతులు. \n",
            "\n",
            "Source: \"Today, most living things use oxygen to make ATP from glucose. However, many living things can also make ATP without oxygen. This is true of some plants and fungi and also of many bacteria. These organisms use aerobic respiration when oxygen is present, but when oxygen is in short supply, they use anaerobic respiration instead. Certain bacteria can only use anaerobic respiration. In fact, they may not be able to survive at all in the presence of oxygen.\"\n",
            "Translation: నేడు, చాలా జీవులు గ్లూకోజ్ నుండి ATP ని తయారు చేయడానికి ఆక్సిజన్ను ఉపయోగిస్తున్నాయి. అయితే, చాలా జీవులు ఆక్సిజన్ లేకుండా ATP ని కూడా తయారు చేయగలవు. ఇది కొన్ని మొక్కలు మరియు శిలీంధ్రాలకు మరియు అనేక బ్యాక్టీరియాలకు కూడా వర్తిస్తుంది. ఈ జీవులు ఆక్సిజన్ ఉన్నప్పుడు ఏరోబిక్ శ్వాసక్రియను ఉపయోగిస్తాయి, కానీ ఆక్సిజన్ కొరత ఉన్నప్పుడు, అవి వాయురహిత శ్వాసక్రియను ఉపయోగిస్తాయి. కొన్ని బ్యాక్టీరియా వాయురహిత శ్వాసక్రియను మాత్రమే ఉపయోగించగలవు. వాస్తవానికి, అవి ఆక్సిజన్ సమక్షంలో అస్సలు జీవించలేకపోవచ్చు. \n",
            "\n",
            "Source: \"Feldspar and quartz are the two most common silicates. In beryl, the silicate pyramids join together as rings. Biotite is mica. It can be broken apart into thin, flexible sheets. Compare the beryl and the biotite shown in Figure below .\"\n",
            "Translation: ఫెల్డ్స్పార్ మరియు క్వార్ట్జ్ రెండు అత్యంత సాధారణ సిలికేట్లు. బెరీల్లో, సిలికేట్ పిరమిడ్లు వలయాలుగా కలిసిపోతాయి. బయోటైట్ మైకా. దీనిని సన్నని, వశ్యమైన పలకలుగా విభజించవచ్చు. బెరిల్ మరియు బయోటైట్ను క్రింది చిత్రంలో పోల్చండి. \n",
            "\n",
            "Source: Humidity is the amount of water vapor in the air. High humidity increases the chances of clouds and precipitation.\n",
            "Translation: తేమ అంటే గాలిలో నీటి ఆవిరి పరిమాణం. అధిక తేమ మేఘాలు మరియు వర్షపాతం వచ్చే అవకాశాలను పెంచుతుంది. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EkNqJ98RUHUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YW1S0IS7opJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jes0PdZfopF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KYdFh6TxopDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DgjZ7Bz6opAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aexs838TG6uQ"
      },
      "outputs": [],
      "source": [
        "#v1\n",
        "%%capture\n",
        "!git clone https://github.com/AI4Bharat/IndicTrans2.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtCFppWkG6uQ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%cd /content/IndicTrans2/huggingface_interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSnvpzsQG6uQ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!python3 -m pip install nltk sacremoses pandas regex mock transformers>=4.33.2 mosestokenizer\n",
        "!python3 -c \"import nltk; nltk.download('punkt')\"\n",
        "!python3 -m pip install bitsandbytes scipy accelerate datasets\n",
        "!python3 -m pip install sentencepiece\n",
        "\n",
        "!git clone https://github.com/VarunGumma/IndicTransToolkit.git\n",
        "%cd IndicTransToolkit\n",
        "!python3 -m pip install --editable ./\n",
        "%cd ..\n",
        "\n",
        "#restart session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dk5799UA2Euz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3d0726e-54d3-46a6-9b33-3354420e3e7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files extracted to: fine_tuned_model_telugu_Scientific_dataset\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "def unzip_file(zip_file_path, extract_to_path):\n",
        "    \"\"\"Unzips a ZIP file to a specified directory.\"\"\"\n",
        "    os.makedirs(extract_to_path, exist_ok=True)  # Create extraction directory\n",
        "\n",
        "    try:\n",
        "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_to_path)  # Extract all contents\n",
        "        print(f\"Files extracted to: {extract_to_path}\")\n",
        "    except (zipfile.BadZipFile, FileNotFoundError):\n",
        "        print(\"Error: Invalid ZIP file or file not found.\")\n",
        "\n",
        "# Example usage\n",
        "unzip_file('/content/fine_tuned_model_telugu_Scientific_dataset.zip', 'fine_tuned_model_telugu_Scientific_dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQi0x-mlWhxC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSeq2SeqLM, BitsAndBytesConfig, AutoTokenizer\n",
        "from IndicTransToolkit import IndicProcessor\n",
        "\n",
        "BATCH_SIZE = 4\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "quantization = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSQ3SmlCG7Rr",
        "outputId": "299db519-7021-4264-e010-b95cd97794ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.45.0-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.5)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.37.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading streamlit-1.45.0-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.45.0 watchdog-6.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets torch transformers streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WetRc7rg9WE2"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Save the Streamlit script in Colab\n",
        "with open('app.py', 'w') as f:\n",
        "    f.write(\"\"\"\n",
        "# app.py\n",
        "\n",
        "import streamlit as st\n",
        "import torch\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from peft import PeftModel\n",
        "from IndicTransToolkit import IndicProcessor\n",
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Title\n",
        "st.title(\"IndicTrans2 - Scientific Sentence Translator (English ➝ Telugu)\")\n",
        "\n",
        "model_dir = \"/content/fine_tuned_model_telugu_Scientific_dataset\"\n",
        "\n",
        "if True:\n",
        "\n",
        "    # Load tokenizer and model\n",
        "    with st.spinner(\"Loading model...\"):\n",
        "        base_ckpt_dir = \"ai4bharat/indictrans2-en-indic-dist-200M\"\n",
        "        tokenizer = AutoTokenizer.from_pretrained(base_ckpt_dir, trust_remote_code=True)\n",
        "        base_model = AutoModelForSeq2SeqLM.from_pretrained(base_ckpt_dir, trust_remote_code=True)\n",
        "        lora_model = PeftModel.from_pretrained(base_model, model_dir)\n",
        "\n",
        "        DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        lora_model.to(DEVICE)\n",
        "\n",
        "        ip = IndicProcessor(inference=True)\n",
        "    st.success(\"Model loaded successfully!\")\n",
        "\n",
        "    # Input box\n",
        "    sentence = st.text_area(\"Enter a scientific sentence in English:\")\n",
        "\n",
        "    if st.button(\"Translate\"):\n",
        "        if sentence.strip():\n",
        "            src_lang, tgt_lang = \"eng_Latn\", \"tel_Telu\"\n",
        "            batch = ip.preprocess_batch([sentence], src_lang=src_lang, tgt_lang=tgt_lang)\n",
        "\n",
        "            inputs = tokenizer(\n",
        "                batch,\n",
        "                truncation=True,\n",
        "                padding=\"longest\",\n",
        "                return_tensors=\"pt\"\n",
        "            ).to(DEVICE)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                generated_tokens = lora_model.generate(\n",
        "                    **inputs,\n",
        "                    use_cache=True,\n",
        "                    min_length=0,\n",
        "                    max_length=256,\n",
        "                    num_beams=5,\n",
        "                    num_return_sequences=1,\n",
        "                )\n",
        "\n",
        "            with tokenizer.as_target_tokenizer():\n",
        "                translation = tokenizer.batch_decode(\n",
        "                    generated_tokens.detach().cpu().tolist(),\n",
        "                    skip_special_tokens=True,\n",
        "                    clean_up_tokenization_spaces=True,\n",
        "                )\n",
        "\n",
        "            final_output = ip.postprocess_batch(translation, lang=tgt_lang)\n",
        "            st.text_area(\"Telugu Translation:\", value=final_output[0], height=150)\n",
        "        else:\n",
        "            st.warning(\"Please enter a sentence to translate.\")\n",
        "\n",
        "    \"\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NClwjlsfO0ze",
        "outputId": "3218601d-c8b9-478b-e53a-ea0a751a7d43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.19.49.110\n"
          ]
        }
      ],
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFzFZp-hLxKQ",
        "outputId": "86b5cf18-b9df-4404-aaf2-18168e4e76e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K\n",
            "added 22 packages in 4s\n",
            "\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0Kyour url is: https://puny-lies-sell.loca.lt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!npm install localtunnel\n",
        "\n",
        "!streamlit run app.py &>/content/logs.txt &\n",
        "\n",
        "!npx localtunnel --port 8501\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#The process of mitosis ensures that each daughter cell receives an identical set of chromosomes, maintaining genetic continuity during cell division."
      ],
      "metadata": {
        "id": "4yrkzaxxoo-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HOftaOj_oo7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xjNMt2GJoo4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1VBrUESeoo19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E4d9QTmBoozZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LEiUtp1-oow2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pz97dH3MoouU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FPzewKRBoors"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QfdrS05Iooo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XBJ9x4Luoomh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lYDzs81XookG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aFUrSp72oohs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}